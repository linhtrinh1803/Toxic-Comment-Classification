{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "source": [
    "# Read and Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "#import re, spacy, string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T00:01:39.779327Z",
     "iopub.status.busy": "2023-03-23T00:01:39.778600Z",
     "iopub.status.idle": "2023-03-23T00:01:41.254370Z",
     "shell.execute_reply": "2023-03-23T00:01:41.252759Z",
     "shell.execute_reply.started": "2023-03-23T00:01:39.779263Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.8.8 (default, Apr 13 2021, 12:59:45) \n",
      "[Clang 10.0.0 ]\n",
      "Version info.: sys.version_info(major=3, minor=8, micro=8, releaselevel='final', serial=0)\n",
      "pandas version: 1.2.4\n",
      "numpy version: 1.20.1\n",
      "skearn version: 0.24.1\n",
      "re version: 2.2.1\n",
      "nltk version: 3.6.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "\n",
    "# Libraries and packages for text (pre-)processing \n",
    "import string\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "print(\"Python version:\", sys.version)\n",
    "print(\"Version info.:\", sys.version_info)\n",
    "print(\"pandas version:\", pd.__version__)\n",
    "print(\"numpy version:\", np.__version__)\n",
    "print(\"skearn version:\", sklearn.__version__)\n",
    "print(\"re version:\", re.__version__)\n",
    "print(\"nltk version:\", nltk.__version__)\n",
    "\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T00:02:31.342747Z",
     "iopub.status.busy": "2023-03-23T00:02:31.342202Z",
     "iopub.status.idle": "2023-03-23T00:02:33.739980Z",
     "shell.execute_reply": "2023-03-23T00:02:33.738330Z",
     "shell.execute_reply.started": "2023-03-23T00:02:31.342675Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159571, 8)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# read the csv file\n",
    "train_df = pd.read_csv(\"/Users/linhtrinh/Downloads/train.csv\")\n",
    "display(train_df.shape, train_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Data\n",
    "\n",
    "\n",
    "### 1. Remove Capitalization\n",
    "\n",
    "Because of the variety of capitalization used to construct a sentence, capitalization or lower case is the strategy used in text cleaning most frequently. With this method, every word in the text and document will be projected into the same feature area. If mistakes, slang, acronyms, or informal abbreviations were to be replaced, the issue would only arise in rare instances like the USA or the UK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T00:04:53.514343Z",
     "iopub.status.busy": "2023-03-23T00:04:53.513647Z",
     "iopub.status.idle": "2023-03-23T00:04:53.804516Z",
     "shell.execute_reply": "2023-03-23T00:04:53.803306Z",
     "shell.execute_reply.started": "2023-03-23T00:04:53.514304Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>explanation\\nwhy the edits made under my usern...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>d'aww! he matches this background colour i'm s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>hey man, i'm really not trying to edit war. it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>\"\\nmore\\ni can't make any real suggestions on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>you, sir, are my hero. any chance you remember...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \\\n",
       "0             0        0       0       0              0   \n",
       "1             0        0       0       0              0   \n",
       "2             0        0       0       0              0   \n",
       "3             0        0       0       0              0   \n",
       "4             0        0       0       0              0   \n",
       "\n",
       "                                          text_clean  \n",
       "0  explanation\\nwhy the edits made under my usern...  \n",
       "1  d'aww! he matches this background colour i'm s...  \n",
       "2  hey man, i'm really not trying to edit war. it...  \n",
       "3  \"\\nmore\\ni can't make any real suggestions on ...  \n",
       "4  you, sir, are my hero. any chance you remember...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df[\"text_clean\"] = train_df[\"comment_text\"].apply(lambda x: x.lower())\n",
    "display(train_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.Expanding Contractions\n",
    "\n",
    "Example of contraction: We'll -> We will, or we shoudn't've -> we should not have. By using Contractions package to expand contractions in English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T00:02:41.164122Z",
     "iopub.status.busy": "2023-03-23T00:02:41.163688Z",
     "iopub.status.idle": "2023-03-23T00:02:56.726324Z",
     "shell.execute_reply": "2023-03-23T00:02:56.724453Z",
     "shell.execute_reply.started": "2023-03-23T00:02:41.164087Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting contractions\n",
      "  Downloading contractions-0.1.73-py2.py3-none-any.whl (8.7 kB)\n",
      "Collecting textsearch>=0.0.21\n",
      "  Downloading textsearch-0.0.24-py2.py3-none-any.whl (7.6 kB)\n",
      "Collecting pyahocorasick\n",
      "  Downloading pyahocorasick-2.0.0-cp38-cp38-macosx_10_9_x86_64.whl (37 kB)\n",
      "Collecting anyascii\n",
      "  Downloading anyascii-0.3.2-py3-none-any.whl (289 kB)\n",
      "\u001b[K     |████████████████████████████████| 289 kB 4.3 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: pyahocorasick, anyascii, textsearch, contractions\n",
      "Successfully installed anyascii-0.3.2 contractions-0.1.73 pyahocorasick-2.0.0 textsearch-0.0.24\n"
     ]
    }
   ],
   "source": [
    "!pip install contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T00:05:01.108094Z",
     "iopub.status.busy": "2023-03-23T00:05:01.107627Z",
     "iopub.status.idle": "2023-03-23T00:05:07.095245Z",
     "shell.execute_reply": "2023-03-23T00:05:07.093690Z",
     "shell.execute_reply.started": "2023-03-23T00:05:01.108055Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test:  \n",
      "            You all cannot expand contractions I would think. I would like to know how I would done that! \n",
      "            We are going to the zoo and I do not think I will be home for dinner.\n",
      "            They Are going to the zoo and she will be home for dinner.\n",
      "            We should have do it in here but we should not have eat it\n",
      "            \n"
     ]
    }
   ],
   "source": [
    "import contractions\n",
    "\n",
    "# Test\n",
    "test_text = \"\"\"\n",
    "            Y'all can't expand contractions I'd think. I'd like to know how I'd done that! \n",
    "            We're going to the zoo and I don't think I'll be home for dinner.\n",
    "            Theyre going to the zoo and she'll be home for dinner.\n",
    "            We should've do it in here but we shouldn't've eat it\n",
    "            \"\"\"\n",
    "print(\"Test: \", contractions.fix(test_text))\n",
    "\n",
    "train_df[\"text_clean\"] = train_df[\"text_clean\"].apply(lambda x: contractions.fix(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T00:05:07.099893Z",
     "iopub.status.busy": "2023-03-23T00:05:07.099426Z",
     "iopub.status.idle": "2023-03-23T00:05:07.111377Z",
     "shell.execute_reply": "2023-03-23T00:05:07.109668Z",
     "shell.execute_reply.started": "2023-03-23T00:05:07.099852Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hey... what is it..\n",
      "@ | talk .\n",
      "What is it... an exclusive group of some WP TALIBANS...who are good at destroying, self-appointed purist who GANG UP any one who asks them questions abt their ANTI-SOCIAL and DESTRUCTIVE (non)-contribution at WP?\n",
      "\n",
      "Ask Sityush to clean up his behavior than issue me nonsensical warnings...\n",
      "hey... what is it..\n",
      "@ | talk .\n",
      "what is it... an exclusive group of some wp talibans...who are good at destroying, self-appointed purist who gang up any one who asks them questions about their anti-social and destructive (non)-contribution at wp?\n",
      "\n",
      "ask sityush to clean up his behavior than issue me nonsensical warnings...\n"
     ]
    }
   ],
   "source": [
    "print(train_df[\"comment_text\"][12]) #notice gang ip, wp\n",
    "print(train_df[\"text_clean\"][12])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Noise Removal\n",
    "\n",
    "Removing unnecessary characters or punctuation such as URLs, HTML tags, non-ASCII characters (American Standard Code for Information Interchange), or other special characters (symbols, emojis, and other grahic characters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Remove URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T00:05:14.254980Z",
     "iopub.status.busy": "2023-03-23T00:05:14.254526Z",
     "iopub.status.idle": "2023-03-23T00:05:14.261918Z",
     "shell.execute_reply": "2023-03-23T00:05:14.260188Z",
     "shell.execute_reply.started": "2023-03-23T00:05:14.254926Z"
    }
   },
   "outputs": [],
   "source": [
    "def remove_URL(text):\n",
    "    \"\"\"\n",
    "        Remove URLs from a sample string\n",
    "    \"\"\"\n",
    "    return re.sub(r\"https?://\\S+|www\\.\\S+\", \"\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T00:05:15.041282Z",
     "iopub.status.busy": "2023-03-23T00:05:15.039859Z",
     "iopub.status.idle": "2023-03-23T00:05:15.892581Z",
     "shell.execute_reply": "2023-03-23T00:05:15.891063Z",
     "shell.execute_reply.started": "2023-03-23T00:05:15.041222Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check the following websites:\n",
      "\n",
      "http://www.iranchamber.com/personalities/farabi/farabi.php\n",
      "http://www.islam.org.br/%C2%A0al_farabi.htm\n",
      "http://www.superbeyin.com/sohbet/sohbet.htm\n",
      "check the following websites:\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# remove urls from the text\n",
    "train_df[\"text_clean\"] = train_df[\"text_clean\"].apply(lambda x: remove_URL(x))\n",
    "\n",
    "# double check\n",
    "print(train_df[\"comment_text\"][101])\n",
    "print(train_df[\"text_clean\"][101])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T00:05:17.377095Z",
     "iopub.status.busy": "2023-03-23T00:05:17.376433Z",
     "iopub.status.idle": "2023-03-23T00:05:17.385597Z",
     "shell.execute_reply": "2023-03-23T00:05:17.383749Z",
     "shell.execute_reply.started": "2023-03-23T00:05:17.377023Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transliteration of Russian place names\n",
      "In writing about Moscow Metro for the Malayalam Wikipedia, we are finding it difficult to correctly transliterate the Russian place names. For example, do we pronounce Park Kultury as PAARK KALTTARI or PAARK KALCHCHARI (or perhaps something completely different)? Can somebody please help by transliterating the list given in https://ml.wikipedia.org/wiki/സംവാദം:മോസ്കോ_മെട്രോ. (I am not putting the list here as I don't want to clutter up this page.) Thanks\n",
      "transliteration of russian place names\n",
      "in writing about moscow metro for the malayalam wikipedia, we are finding it difficult to correctly transliterate the russian place names. for example, do we pronounce park kultury as paark kalttari or paark kalchchari (or perhaps something completely different)? can somebody please help by transliterating the list given in  (i am not putting the list here as i do not want to clutter up this page.) thanks\n"
     ]
    }
   ],
   "source": [
    "print(train_df[\"comment_text\"][91]) #notice the url\n",
    "print(train_df[\"text_clean\"][91])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Remove HTML Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T00:06:36.986448Z",
     "iopub.status.busy": "2023-03-23T00:06:36.985861Z",
     "iopub.status.idle": "2023-03-23T00:06:36.993820Z",
     "shell.execute_reply": "2023-03-23T00:06:36.992233Z",
     "shell.execute_reply.started": "2023-03-23T00:06:36.986405Z"
    }
   },
   "outputs": [],
   "source": [
    "def remove_html(text):\n",
    "    \"\"\"\n",
    "        Remove the html in sample text\n",
    "    \"\"\"\n",
    "    html = re.compile(r\"<.*?>|&([a-z0-9]+|#[0-9]{1,6}|#x[0-9a-f]{1,6});\")\n",
    "    return re.sub(html, \"\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T00:06:38.431147Z",
     "iopub.status.busy": "2023-03-23T00:06:38.430610Z",
     "iopub.status.idle": "2023-03-23T00:06:39.368828Z",
     "shell.execute_reply": "2023-03-23T00:06:39.367260Z",
     "shell.execute_reply.started": "2023-03-23T00:06:38.431105Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Also see this if you cant trust Murkoth Ramunni\n",
      "http://books.google.com/books?id=HHev0U1GfpEC&pg;=PA51&dq;=Thiyya+matrilineal&hl;=en&sa;=X&ei;=TlpPUd2aH8mWiQLgvIDgBA&ved;=0CDYQ6AEwAQ#v=onepage&q;=Thiyya%20matrilineal&f;=false\n",
      "also see this if you cannot trust murkoth ramunni\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# remove html from the text\n",
    "train_df[\"text_clean\"] = train_df[\"text_clean\"].apply(lambda x: remove_html(x))\n",
    "\n",
    "# double check\n",
    "print(train_df[\"comment_text\"][117]) #notice the url is gone\n",
    "print(train_df[\"text_clean\"][117])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Remove Non-ASCII"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T00:06:41.185504Z",
     "iopub.status.busy": "2023-03-23T00:06:41.184991Z",
     "iopub.status.idle": "2023-03-23T00:06:41.192477Z",
     "shell.execute_reply": "2023-03-23T00:06:41.190665Z",
     "shell.execute_reply.started": "2023-03-23T00:06:41.185460Z"
    }
   },
   "outputs": [],
   "source": [
    "def remove_non_ascii(text):\n",
    "    \"\"\"\n",
    "        Remove non-ASCII characters \n",
    "    \"\"\"\n",
    "    return re.sub(r'[^\\x00-\\x7f]',r'', text) # or ''.join([x for x in text if x in string.printable]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T00:06:42.304550Z",
     "iopub.status.busy": "2023-03-23T00:06:42.304074Z",
     "iopub.status.idle": "2023-03-23T00:06:43.030685Z",
     "shell.execute_reply": "2023-03-23T00:06:43.029348Z",
     "shell.execute_reply.started": "2023-03-23T00:06:42.304509Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\n",
      "No, we don't.  The name \"\"Ivory Coast\"\" contains only English-alphabet letters, and it would sort just fine in almost all cases where \"\"Côte d'Ivoire\"\" remains missorted, often appearing after Croatia, after Cyprus, after Czech Republic.  You can see this by looking at Category:Communications by country and seeing where the subcategory Category:Communications in Côte d'Ivoire is missorted (even though the sorting of the article of the same name has been fixed—can you see the difference in order?).  Or you can see it by looking at Category:Nations at the 2004 Summer Olympics and seeing where the article Côte d'Ivoire at the 2004 Summer Olympics is missorted.\n",
      "There are hundreds of those problems out there.  Why don't you make yourself useful, and go fix some of them?   \n",
      "\n",
      "\"\n",
      "\"\n",
      "no, we do not.  the name \"\"ivory coast\"\" contains only english-alphabet letters, and it would sort just fine in almost all cases where \"\"cte d'ivoire\"\" remains missorted, often appearing after croatia, after cyprus, after czech republic.  you can see this by looking at category:communications by country and seeing where the subcategory category:communications in cte d'ivoire is missorted (even though the sorting of the article of the same name has been fixedcan you see the difference in order?).  or you can see it by looking at category:nations at the 2004 summer olympics and seeing where the article cte d'ivoire at the 2004 summer olympics is missorted.\n",
      "there are hundreds of those problems out there.  why do not you make yourself useful, and go fix some of them?   \n",
      "\n",
      "\"\n"
     ]
    }
   ],
   "source": [
    "# remove non-ascii characters from the text\n",
    "train_df[\"text_clean\"] = train_df[\"text_clean\"].apply(lambda x: remove_non_ascii(x))\n",
    "\n",
    "# double che\n",
    "print(train_df[\"comment_text\"][6011]) #notice Côte on the 2nd line\n",
    "print(train_df[\"text_clean\"][6011])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T00:06:45.489411Z",
     "iopub.status.busy": "2023-03-23T00:06:45.488382Z",
     "iopub.status.idle": "2023-03-23T00:06:45.497227Z",
     "shell.execute_reply": "2023-03-23T00:06:45.495335Z",
     "shell.execute_reply.started": "2023-03-23T00:06:45.489364Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amazons, after all\n",
      "I think I found the source of the connection of the labrys with the amazons: sagaris \n",
      "\n",
      " saga^ris , eôs Ion. ios, hê; pl. sagareis Ion. -i_s:a weapon used by the Scythian tribes, Hdt.1.215, 4.5;\n",
      "\n",
      " A. axinas sagaris eichon Id.7.64 ; by the Amazons, Aristarch. in \n",
      " PAmh.2.12 ii 10; by the Persians, Amazons, Mossynoeci, etc., \n",
      " X.An.4.4.16, 5.4.13:acc. to Hsch. single-edged, and joined by \n",
      " X. with kopis and machaira, Cyr. 1.2.9, 2.1.9, 4.2.22; \n",
      " double-edged acc. to AP6.94 (Phil.).\n",
      "\n",
      "i.e. an axe-like weapon, sometimes described as single-edged, and sometimes as double-edged. This shouild probably be put in a Sagaris article.\n",
      "amazons, after all\n",
      "i think i found the source of the connection of the labrys with the amazons: sagaris \n",
      "\n",
      " saga^ris , es ion. ios, h; pl. sagareis ion. -i_s:a weapon used by the scythian tribes, hdt.1.215, 4.5;\n",
      "\n",
      " a. axinas sagaris eichon id.7.64 ; by the amazons, aristarch. in \n",
      " pamh.2.12 ii 10; by the persians, amazons, mossynoeci, etc., \n",
      " x.an.4.4.16, 5.4.13:acc. to hsch. single-edged, and joined by \n",
      " x. with kopis and machaira, cyr. 1.2.9, 2.1.9, 4.2.22; \n",
      " double-edged acc. to ap6.94 (phil.).\n",
      "\n",
      "i.e. an axe-like weapon, sometimes described as single-edged, and sometimes as double-edged. this shouild probably be put in a sagaris article.\n"
     ]
    }
   ],
   "source": [
    "print(train_df[\"comment_text\"][7814]) #notice eôs\n",
    "print(train_df[\"text_clean\"][7814])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4 Remove Special Characters\n",
    "\n",
    "Special characters could be symbols, emojis, and other graphic characters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T00:06:48.307797Z",
     "iopub.status.busy": "2023-03-23T00:06:48.306744Z",
     "iopub.status.idle": "2023-03-23T00:06:48.315762Z",
     "shell.execute_reply": "2023-03-23T00:06:48.314239Z",
     "shell.execute_reply.started": "2023-03-23T00:06:48.307726Z"
    }
   },
   "outputs": [],
   "source": [
    "def remove_special_characters(text):\n",
    "    \"\"\"\n",
    "        Remove special special characters, including symbols, emojis, and other graphic characters\n",
    "    \"\"\"\n",
    "    emoji_pattern = re.compile(\n",
    "        '['\n",
    "        u'\\U0001F600-\\U0001F64F'  # emoticons\n",
    "        u'\\U0001F300-\\U0001F5FF'  # symbols & pictographs\n",
    "        u'\\U0001F680-\\U0001F6FF'  # transport & map symbols\n",
    "        u'\\U0001F1E0-\\U0001F1FF'  # flags (iOS)\n",
    "        u'\\U00002702-\\U000027B0'\n",
    "        u'\\U000024C2-\\U0001F251'\n",
    "        ']+',\n",
    "        flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T00:06:49.441999Z",
     "iopub.status.busy": "2023-03-23T00:06:49.441446Z",
     "iopub.status.idle": "2023-03-23T00:06:51.405525Z",
     "shell.execute_reply": "2023-03-23T00:06:51.404235Z",
     "shell.execute_reply.started": "2023-03-23T00:06:49.441939Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df[\"text_clean\"] = train_df[\"text_clean\"].apply(lambda x: remove_special_characters(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T00:06:51.408352Z",
     "iopub.status.busy": "2023-03-23T00:06:51.407588Z",
     "iopub.status.idle": "2023-03-23T00:06:51.417030Z",
     "shell.execute_reply": "2023-03-23T00:06:51.415454Z",
     "shell.execute_reply.started": "2023-03-23T00:06:51.408307Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"P.S. It's not polite to talk to people behind their backs, please remove your comments from Mrph's talk page.\n",
      "\n",
      "Vaughan\n",
      "You're right; I went to check your previous edit and found a page on the Marvel site that spelled it \"\"Vaughn\"\", but now I am finding many more that spell it correctly. Thanks for the edits.   (☎☓) \n",
      "\n",
      "\"\n",
      "\"p.s. it is not polite to talk to people behind their backs, please remove your comments from mrph's talk page.\n",
      "\n",
      "vaughan\n",
      "you are right; i went to check your previous edit and found a page on the marvel site that spelled it \"\"vaughn\"\", but now i am finding many more that spell it correctly. thanks for the edits.   () \n",
      "\n",
      "\"\n"
     ]
    }
   ],
   "source": [
    "# double check\n",
    "print(train_df[\"comment_text\"][143]) #notice the telephone\n",
    "print(train_df[\"text_clean\"][143])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T00:06:51.948621Z",
     "iopub.status.busy": "2023-03-23T00:06:51.947445Z",
     "iopub.status.idle": "2023-03-23T00:06:51.956166Z",
     "shell.execute_reply": "2023-03-23T00:06:51.954469Z",
     "shell.execute_reply.started": "2023-03-23T00:06:51.948569Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\n",
      "\n",
      "Sorry to interrupt but I'm at 1200 edits now... the first 200 were likely just on my own pages and because I was asking for help so much so maybe just 1000... or maybe less... but it still kind of counts. ♥♥Amulet♥♥ \"\n",
      "\"\n",
      "\n",
      "sorry to interrupt but i am at 1200 edits now... the first 200 were likely just on my own pages and because i was asking for help so much so maybe just 1000... or maybe less... but it still kind of counts. amulet \"\n"
     ]
    }
   ],
   "source": [
    "print(train_df[\"comment_text\"][189]) #notice the heart\n",
    "print(train_df[\"text_clean\"][189])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5 Remove Punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T00:06:55.990792Z",
     "iopub.status.busy": "2023-03-23T00:06:55.989536Z",
     "iopub.status.idle": "2023-03-23T00:06:55.997833Z",
     "shell.execute_reply": "2023-03-23T00:06:55.996242Z",
     "shell.execute_reply.started": "2023-03-23T00:06:55.990741Z"
    }
   },
   "outputs": [],
   "source": [
    "def remove_punct(text):\n",
    "    \"\"\"\n",
    "        Remove the punctuation\n",
    "    \"\"\"\n",
    "#     return re.sub(r'[]!\"$%&\\'()*+,./:;=#@?[\\\\^_`{|}~-]+', \"\", text)\n",
    "    return text.translate(str.maketrans('', '', string.punctuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T00:06:56.568222Z",
     "iopub.status.busy": "2023-03-23T00:06:56.567329Z",
     "iopub.status.idle": "2023-03-23T00:06:57.633692Z",
     "shell.execute_reply": "2023-03-23T00:06:57.632263Z",
     "shell.execute_reply.started": "2023-03-23T00:06:56.568176Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\n",
      "More\n",
      "I can't make any real suggestions on improvement - I wondered if the section statistics should be later on, or a subsection of \"\"types of accidents\"\"  -I think the references may need tidying so that they are all in the exact same format ie date format etc. I can do that later on, if no-one else does first - if you have any preferences for formatting style on references or want to do it yourself please let me know.\n",
      "\n",
      "There appears to be a backlog on articles for review so I guess there may be a delay until a reviewer turns up. It's listed in the relevant form eg Wikipedia:Good_article_nominations#Transport  \"\n",
      "\n",
      "more\n",
      "i cannot make any real suggestions on improvement  i wondered if the section statistics should be later on or a subsection of types of accidents  i think the references may need tidying so that they are all in the exact same format ie date format etc i can do that later on if noone else does first  if you have any preferences for formatting style on references or want to do it yourself please let me know\n",
      "\n",
      "there appears to be a backlog on articles for review so i guess there may be a delay until a reviewer turns up it is listed in the relevant form eg wikipediagoodarticlenominationstransport  \n"
     ]
    }
   ],
   "source": [
    "train_df[\"text_clean\"] = train_df[\"text_clean\"].apply(lambda x: remove_punct(x))\n",
    "\n",
    "# double check\n",
    "print(train_df[\"comment_text\"][3])\n",
    "print(train_df[\"text_clean\"][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T00:07:02.833817Z",
     "iopub.status.busy": "2023-03-23T00:07:02.833300Z",
     "iopub.status.idle": "2023-03-23T00:07:02.840840Z",
     "shell.execute_reply": "2023-03-23T00:07:02.839498Z",
     "shell.execute_reply.started": "2023-03-23T00:07:02.833777Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\n",
      "\n",
      "I don't see a problem with citing GAO/HRD-87-46 and the pdf linked there. The \"\"internal FDA documents\"\" sound like they are by definition not published.  Talk \"\n",
      "\n",
      "\n",
      "i do not see a problem with citing gaohrd8746 and the pdf linked there the internal fda documents sound like they are by definition not published  talk \n"
     ]
    }
   ],
   "source": [
    "print(train_df[\"comment_text\"][7595])\n",
    "print(train_df[\"text_clean\"][7595])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.6 Other Manual Text Cleaning Tasks\n",
    "\n",
    "- Replace Unicode characters with equivalent ASCII character (instead of removing)\n",
    "- Replace the entity references with their actual symbols instead of removing as HTML tags\n",
    "- Replace the Typos, slang, acronyms or informal abbreviations - depends on diffrent situations or main topics of the NLP such as finance or medical topics. \n",
    "- List out all the hashtags/ usernames then replace with equivalent words. \n",
    "- Replace the emoticon/ emoji with equivalent word meaning such as \":)\" with \"smile\" \n",
    "- Spelling correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T00:07:04.669589Z",
     "iopub.status.busy": "2023-03-23T00:07:04.668120Z",
     "iopub.status.idle": "2023-03-23T00:07:04.713585Z",
     "shell.execute_reply": "2023-03-23T00:07:04.711938Z",
     "shell.execute_reply.started": "2023-03-23T00:07:04.669509Z"
    }
   },
   "outputs": [],
   "source": [
    "def other_clean(text):\n",
    "        \"\"\"\n",
    "            Other manual text cleaning techniques\n",
    "        \"\"\"\n",
    "        # Typos, slang and other\n",
    "        sample_typos_slang = {\n",
    "                                \"w/e\": \"whatever\",\n",
    "                                \"usagov\": \"usa government\",\n",
    "                                \"recentlu\": \"recently\",\n",
    "                                \"ph0tos\": \"photos\",\n",
    "                                \"amirite\": \"am i right\",\n",
    "                                \"exp0sed\": \"exposed\",\n",
    "                                \"<3\": \"love\",\n",
    "                                \"luv\": \"love\",\n",
    "                                \"amageddon\": \"armageddon\",\n",
    "                                \"trfc\": \"traffic\",\n",
    "                                \"16yr\": \"16 year\"\n",
    "                                }\n",
    "\n",
    "        # Acronyms\n",
    "        sample_acronyms =  { \n",
    "                            \"mh370\": \"malaysia airlines flight 370\",\n",
    "                            \"okwx\": \"oklahoma city weather\",\n",
    "                            \"arwx\": \"arkansas weather\",    \n",
    "                            \"gawx\": \"georgia weather\",  \n",
    "                            \"scwx\": \"south carolina weather\",  \n",
    "                            \"cawx\": \"california weather\",\n",
    "                            \"tnwx\": \"tennessee weather\",\n",
    "                            \"azwx\": \"arizona weather\",  \n",
    "                            \"alwx\": \"alabama weather\",\n",
    "                            \"usnwsgov\": \"united states national weather service\",\n",
    "                            \"2mw\": \"tomorrow\"\n",
    "                            }\n",
    "\n",
    "        # Some common abbreviations \n",
    "        sample_abbr = {\n",
    "                        \"$\" : \" dollar \",\n",
    "                        \"€\" : \" euro \",\n",
    "                        \"4ao\" : \"for adults only\",\n",
    "                        \"a.m\" : \"before midday\",\n",
    "                        \"a3\" : \"anytime anywhere anyplace\",\n",
    "                        \"aamof\" : \"as a matter of fact\",\n",
    "                        \"acct\" : \"account\",\n",
    "                        \"adih\" : \"another day in hell\",\n",
    "                        \"afaic\" : \"as far as i am concerned\",\n",
    "                        \"afaict\" : \"as far as i can tell\",\n",
    "                        \"afaik\" : \"as far as i know\",\n",
    "                        \"afair\" : \"as far as i remember\",\n",
    "                        \"afk\" : \"away from keyboard\",\n",
    "                        \"app\" : \"application\",\n",
    "                        \"approx\" : \"approximately\",\n",
    "                        \"apps\" : \"applications\",\n",
    "                        \"asap\" : \"as soon as possible\",\n",
    "                        \"asl\" : \"age, sex, location\",\n",
    "                        \"atk\" : \"at the keyboard\",\n",
    "                        \"ave.\" : \"avenue\",\n",
    "                        \"aymm\" : \"are you my mother\",\n",
    "                        \"ayor\" : \"at your own risk\", \n",
    "                        \"b&b\" : \"bed and breakfast\",\n",
    "                        \"b+b\" : \"bed and breakfast\",\n",
    "                        \"b.c\" : \"before christ\",\n",
    "                        \"b2b\" : \"business to business\",\n",
    "                        \"b2c\" : \"business to customer\",\n",
    "                        \"b4\" : \"before\",\n",
    "                        \"b4n\" : \"bye for now\",\n",
    "                        \"b@u\" : \"back at you\",\n",
    "                        \"bae\" : \"before anyone else\",\n",
    "                        \"bak\" : \"back at keyboard\",\n",
    "                        \"bbbg\" : \"bye bye be good\",\n",
    "                        \"bbc\" : \"british broadcasting corporation\",\n",
    "                        \"bbias\" : \"be back in a second\",\n",
    "                        \"bbl\" : \"be back later\",\n",
    "                        \"bbs\" : \"be back soon\",\n",
    "                        \"be4\" : \"before\",\n",
    "                        \"bfn\" : \"bye for now\",\n",
    "                        \"blvd\" : \"boulevard\",\n",
    "                        \"bout\" : \"about\",\n",
    "                        \"brb\" : \"be right back\",\n",
    "                        \"bros\" : \"brothers\",\n",
    "                        \"brt\" : \"be right there\",\n",
    "                        \"bsaaw\" : \"big smile and a wink\",\n",
    "                        \"btw\" : \"by the way\",\n",
    "                        \"bwl\" : \"bursting with laughter\",\n",
    "                        \"c/o\" : \"care of\",\n",
    "                        \"cet\" : \"central european time\",\n",
    "                        \"cf\" : \"compare\",\n",
    "                        \"cia\" : \"central intelligence agency\",\n",
    "                        \"csl\" : \"can not stop laughing\",\n",
    "                        \"cu\" : \"see you\",\n",
    "                        \"cul8r\" : \"see you later\",\n",
    "                        \"cv\" : \"curriculum vitae\",\n",
    "                        \"cwot\" : \"complete waste of time\",\n",
    "                        \"cya\" : \"see you\",\n",
    "                        \"cyt\" : \"see you tomorrow\",\n",
    "                        \"dae\" : \"does anyone else\",\n",
    "                        \"dbmib\" : \"do not bother me i am busy\",\n",
    "                        \"diy\" : \"do it yourself\",\n",
    "                        \"dm\" : \"direct message\",\n",
    "                        \"dwh\" : \"during work hours\",\n",
    "                        \"e123\" : \"easy as one two three\",\n",
    "                        \"eet\" : \"eastern european time\",\n",
    "                        \"eg\" : \"example\",\n",
    "                        \"embm\" : \"early morning business meeting\",\n",
    "                        \"encl\" : \"enclosed\",\n",
    "                        \"encl.\" : \"enclosed\",\n",
    "                        \"etc\" : \"and so on\",\n",
    "                        \"faq\" : \"frequently asked questions\",\n",
    "                        \"fawc\" : \"for anyone who cares\",\n",
    "                        \"fb\" : \"facebook\",\n",
    "                        \"fc\" : \"fingers crossed\",\n",
    "                        \"fig\" : \"figure\",\n",
    "                        \"fimh\" : \"forever in my heart\", \n",
    "                        \"ft.\" : \"feet\",\n",
    "                        \"ft\" : \"featuring\",\n",
    "                        \"ftl\" : \"for the loss\",\n",
    "                        \"ftw\" : \"for the win\",\n",
    "                        \"fwiw\" : \"for what it is worth\",\n",
    "                        \"fyi\" : \"for your information\",\n",
    "                        \"g9\" : \"genius\",\n",
    "                        \"gahoy\" : \"get a hold of yourself\",\n",
    "                        \"gal\" : \"get a life\",\n",
    "                        \"gcse\" : \"general certificate of secondary education\",\n",
    "                        \"gfn\" : \"gone for now\",\n",
    "                        \"gg\" : \"good game\",\n",
    "                        \"gl\" : \"good luck\",\n",
    "                        \"glhf\" : \"good luck have fun\",\n",
    "                        \"gmt\" : \"greenwich mean time\",\n",
    "                        \"gmta\" : \"great minds think alike\",\n",
    "                        \"gn\" : \"good night\",\n",
    "                        \"g.o.a.t\" : \"greatest of all time\",\n",
    "                        \"goat\" : \"greatest of all time\",\n",
    "                        \"goi\" : \"get over it\",\n",
    "                        \"gps\" : \"global positioning system\",\n",
    "                        \"gr8\" : \"great\",\n",
    "                        \"gratz\" : \"congratulations\",\n",
    "                        \"gyal\" : \"girl\",\n",
    "                        \"h&c\" : \"hot and cold\",\n",
    "                        \"hp\" : \"horsepower\",\n",
    "                        \"hr\" : \"hour\",\n",
    "                        \"hrh\" : \"his royal highness\",\n",
    "                        \"ht\" : \"height\",\n",
    "                        \"ibrb\" : \"i will be right back\",\n",
    "                        \"ic\" : \"i see\",\n",
    "                        \"icq\" : \"i seek you\",\n",
    "                        \"icymi\" : \"in case you missed it\",\n",
    "                        \"idc\" : \"i do not care\",\n",
    "                        \"idgadf\" : \"i do not give a damn fuck\",\n",
    "                        \"idgaf\" : \"i do not give a fuck\",\n",
    "                        \"idk\" : \"i do not know\",\n",
    "                        \"ie\" : \"that is\",\n",
    "                        \"i.e\" : \"that is\",\n",
    "                        \"ifyp\" : \"i feel your pain\",\n",
    "                        \"IG\" : \"instagram\",\n",
    "                        \"iirc\" : \"if i remember correctly\",\n",
    "                        \"ilu\" : \"i love you\",\n",
    "                        \"ily\" : \"i love you\",\n",
    "                        \"imho\" : \"in my humble opinion\",\n",
    "                        \"imo\" : \"in my opinion\",\n",
    "                        \"imu\" : \"i miss you\",\n",
    "                        \"iow\" : \"in other words\",\n",
    "                        \"irl\" : \"in real life\",\n",
    "                        \"j4f\" : \"just for fun\",\n",
    "                        \"jic\" : \"just in case\",\n",
    "                        \"jk\" : \"just kidding\",\n",
    "                        \"jsyk\" : \"just so you know\",\n",
    "                        \"l8r\" : \"later\",\n",
    "                        \"lb\" : \"pound\",\n",
    "                        \"lbs\" : \"pounds\",\n",
    "                        \"ldr\" : \"long distance relationship\",\n",
    "                        \"lmao\" : \"laugh my ass off\",\n",
    "                        \"lmfao\" : \"laugh my fucking ass off\",\n",
    "                        \"lol\" : \"laughing out loud\",\n",
    "                        \"ltd\" : \"limited\",\n",
    "                        \"ltns\" : \"long time no see\",\n",
    "                        \"m8\" : \"mate\",\n",
    "                        \"mf\" : \"motherfucker\",\n",
    "                        \"mfs\" : \"motherfuckers\",\n",
    "                        \"mfw\" : \"my face when\",\n",
    "                        \"mofo\" : \"motherfucker\",\n",
    "                        \"mph\" : \"miles per hour\",\n",
    "                        \"mr\" : \"mister\",\n",
    "                        \"mrw\" : \"my reaction when\",\n",
    "                        \"ms\" : \"miss\",\n",
    "                        \"mte\" : \"my thoughts exactly\",\n",
    "                        \"nagi\" : \"not a good idea\",\n",
    "                        \"nbc\" : \"national broadcasting company\",\n",
    "                        \"nbd\" : \"not big deal\",\n",
    "                        \"nfs\" : \"not for sale\",\n",
    "                        \"ngl\" : \"not going to lie\",\n",
    "                        \"nhs\" : \"national health service\",\n",
    "                        \"nrn\" : \"no reply necessary\",\n",
    "                        \"nsfl\" : \"not safe for life\",\n",
    "                        \"nsfw\" : \"not safe for work\",\n",
    "                        \"nth\" : \"nice to have\",\n",
    "                        \"nvr\" : \"never\",\n",
    "                        \"nyc\" : \"new york city\",\n",
    "                        \"oc\" : \"original content\",\n",
    "                        \"og\" : \"original\",\n",
    "                        \"ohp\" : \"overhead projector\",\n",
    "                        \"oic\" : \"oh i see\",\n",
    "                        \"omdb\" : \"over my dead body\",\n",
    "                        \"omg\" : \"oh my god\",\n",
    "                        \"omw\" : \"on my way\",\n",
    "                        \"p.a\" : \"per annum\",\n",
    "                        \"p.m\" : \"after midday\",\n",
    "                        \"pm\" : \"prime minister\",\n",
    "                        \"poc\" : \"people of color\",\n",
    "                        \"pov\" : \"point of view\",\n",
    "                        \"pp\" : \"pages\",\n",
    "                        \"ppl\" : \"people\",\n",
    "                        \"prw\" : \"parents are watching\",\n",
    "                        \"ps\" : \"postscript\",\n",
    "                        \"pt\" : \"point\",\n",
    "                        \"ptb\" : \"please text back\",\n",
    "                        \"pto\" : \"please turn over\",\n",
    "                        \"qpsa\" : \"what happens\", #\"que pasa\",\n",
    "                        \"ratchet\" : \"rude\",\n",
    "                        \"rbtl\" : \"read between the lines\",\n",
    "                        \"rlrt\" : \"real life retweet\", \n",
    "                        \"rofl\" : \"rolling on the floor laughing\",\n",
    "                        \"roflol\" : \"rolling on the floor laughing out loud\",\n",
    "                        \"rotflmao\" : \"rolling on the floor laughing my ass off\",\n",
    "                        \"rt\" : \"retweet\",\n",
    "                        \"ruok\" : \"are you ok\",\n",
    "                        \"sfw\" : \"safe for work\",\n",
    "                        \"sk8\" : \"skate\",\n",
    "                        \"smh\" : \"shake my head\",\n",
    "                        \"sq\" : \"square\",\n",
    "                        \"srsly\" : \"seriously\", \n",
    "                        \"ssdd\" : \"same stuff different day\",\n",
    "                        \"tbh\" : \"to be honest\",\n",
    "                        \"tbs\" : \"tablespooful\",\n",
    "                        \"tbsp\" : \"tablespooful\",\n",
    "                        \"tfw\" : \"that feeling when\",\n",
    "                        \"thks\" : \"thank you\",\n",
    "                        \"tho\" : \"though\",\n",
    "                        \"thx\" : \"thank you\",\n",
    "                        \"tia\" : \"thanks in advance\",\n",
    "                        \"til\" : \"today i learned\",\n",
    "                        \"tl;dr\" : \"too long i did not read\",\n",
    "                        \"tldr\" : \"too long i did not read\",\n",
    "                        \"tmb\" : \"tweet me back\",\n",
    "                        \"tntl\" : \"trying not to laugh\",\n",
    "                        \"ttyl\" : \"talk to you later\",\n",
    "                        \"u\" : \"you\",\n",
    "                        \"u2\" : \"you too\",\n",
    "                        \"u4e\" : \"yours for ever\",\n",
    "                        \"utc\" : \"coordinated universal time\",\n",
    "                        \"w/\" : \"with\",\n",
    "                        \"w/o\" : \"without\",\n",
    "                        \"w8\" : \"wait\",\n",
    "                        \"wassup\" : \"what is up\",\n",
    "                        \"wb\" : \"welcome back\",\n",
    "                        \"wtf\" : \"what the fuck\",\n",
    "                        \"wtg\" : \"way to go\",\n",
    "                        \"wtpa\" : \"where the party at\",\n",
    "                        \"wuf\" : \"where are you from\",\n",
    "                        \"wuzup\" : \"what is up\",\n",
    "                        \"wywh\" : \"wish you were here\",\n",
    "                        \"yd\" : \"yard\",\n",
    "                        \"ygtr\" : \"you got that right\",\n",
    "                        \"ynk\" : \"you never know\",\n",
    "                        \"zzz\" : \"sleeping bored and tired\"\n",
    "                        }\n",
    "            \n",
    "        sample_typos_slang_pattern = re.compile(r'(?<!\\w)(' + '|'.join(re.escape(key) for key in sample_typos_slang.keys()) + r')(?!\\w)')\n",
    "        sample_acronyms_pattern = re.compile(r'(?<!\\w)(' + '|'.join(re.escape(key) for key in sample_acronyms.keys()) + r')(?!\\w)')\n",
    "        sample_abbr_pattern = re.compile(r'(?<!\\w)(' + '|'.join(re.escape(key) for key in sample_abbr.keys()) + r')(?!\\w)')\n",
    "        \n",
    "        text = sample_typos_slang_pattern.sub(lambda x: sample_typos_slang[x.group()], text)\n",
    "        text = sample_acronyms_pattern.sub(lambda x: sample_acronyms[x.group()], text)\n",
    "        text = sample_abbr_pattern.sub(lambda x: sample_abbr[x.group()], text)\n",
    "        \n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T00:07:05.882661Z",
     "iopub.status.busy": "2023-03-23T00:07:05.881814Z",
     "iopub.status.idle": "2023-03-23T00:07:57.254492Z",
     "shell.execute_reply": "2023-03-23T00:07:57.253069Z",
     "shell.execute_reply.started": "2023-03-23T00:07:05.882620Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df[\"text_clean\"] = train_df[\"text_clean\"].apply(lambda x: other_clean(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T00:07:57.260446Z",
     "iopub.status.busy": "2023-03-23T00:07:57.259688Z",
     "iopub.status.idle": "2023-03-23T00:07:57.269371Z",
     "shell.execute_reply": "2023-03-23T00:07:57.267762Z",
     "shell.execute_reply.started": "2023-03-23T00:07:57.260402Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"   Please refrain from creating inappropriate pages such as OMG LIEK TOTALLY. It is considered vandalism. If you would like to experiment, use the sandbox.  , Recent changes patrol\"\n",
      "   please refrain from creating inappropriate pages such as oh my god liek totally it is considered vandalism if you would like to experiment use the sandbox   recent changes patrol\n"
     ]
    }
   ],
   "source": [
    "# double check\n",
    "print(train_df[\"comment_text\"][10875]) #notice omg\n",
    "print(train_df[\"text_clean\"][10875])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T00:07:57.271913Z",
     "iopub.status.busy": "2023-03-23T00:07:57.271425Z",
     "iopub.status.idle": "2023-03-23T00:07:57.286858Z",
     "shell.execute_reply": "2023-03-23T00:07:57.285828Z",
     "shell.execute_reply.started": "2023-03-23T00:07:57.271860Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poor Walty is blocked ( LMAO knew it would happen someday.\n",
      "poor walty is blocked  laugh my ass off knew it would happen someday\n"
     ]
    }
   ],
   "source": [
    "print(train_df[\"comment_text\"][20296]) #notice lmao\n",
    "print(train_df[\"text_clean\"][20296])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.7 Spelling Correction (optional)\n",
    "\n",
    "Social media text data are usually typos or mistyped. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-19T05:57:47.601521Z",
     "iopub.status.busy": "2023-03-19T05:57:47.601147Z",
     "iopub.status.idle": "2023-03-19T05:57:47.778777Z",
     "shell.execute_reply": "2023-03-19T05:57:47.777113Z",
     "shell.execute_reply.started": "2023-03-19T05:57:47.601488Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'textblob'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-820edab29ff2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtextblob\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTextBlob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Test: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTextBlob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sleapy and tehre is no plaxe I'm gioong to.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorrect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'textblob'"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "print(\"Test: \", TextBlob(\"sleapy and tehre is no plaxe I'm gioong to.\").correct())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-19T05:57:50.609184Z",
     "iopub.status.busy": "2023-03-19T05:57:50.608818Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df['text_clean'] = train_df['text_clean'].apply(lambda x: TextBlob(x).correct())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-19T05:37:53.440531Z",
     "iopub.status.busy": "2023-03-19T05:37:53.439930Z",
     "iopub.status.idle": "2023-03-19T05:37:53.445959Z",
     "shell.execute_reply": "2023-03-19T05:37:53.445031Z",
     "shell.execute_reply.started": "2023-03-19T05:37:53.440492Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"   Please refrain from creating inappropriate pages such as OMG LIEK TOTALLY. It is considered vandalism. If you would like to experiment, use the sandbox.  , Recent changes patrol\"\n",
      "   Please refrain from creating inappropriate pages such as OMG LIEK TOTALLY It is considered vandalism If you would like to experiment use the sandbox   Recent changes patrol\n"
     ]
    }
   ],
   "source": [
    "# double check\n",
    "print(train_df[\"comment_text\"][10875]) #notice liek is fixed to like \n",
    "print(train_df[\"text_clean\"][10875])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Preprocessing:\n",
    "\n",
    "### 1. Tokenization\n",
    "Tokenization is a common technique that split a sentence into tokens, where a token could be characters, words, phrases, symbols, or other meaningful elements. By breaking sentences into smaller chunks, that would help to investigate the words in a sentence and also the subsequent steps in the NLP pipeline, such as stemming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/linhtrinh/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>snowball_stemmer</th>\n",
       "      <th>tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>explanation\\nwhy the edits made under my usern...</td>\n",
       "      <td>[e, x, p, l, a, n, a, t, i, o, n, \\n, w, h, y,...</td>\n",
       "      <td>[explanation, why, the, edits, made, under, my...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>daww he matches this background colour i am se...</td>\n",
       "      <td>[d, a, w, w,  , h, e,  , m, a, t, c, h, e, s, ...</td>\n",
       "      <td>[daww, he, matches, this, background, colour, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>hey man i am really not trying to edit war it ...</td>\n",
       "      <td>[h, e, y,  , m, a, n,  , i,  , a, m,  , r, e, ...</td>\n",
       "      <td>[hey, man, i, am, really, not, trying, to, edi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>\\nmore\\ni cannot make any real suggestions on ...</td>\n",
       "      <td>[\\n, m, o, r, e, \\n, i,  , c, a, n, n, o, t,  ...</td>\n",
       "      <td>[more, i, can, not, make, any, real, suggestio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>you sir are my hero any chance you remember wh...</td>\n",
       "      <td>[y, o, u,  , s, i, r,  , a, r, e,  , m, y,  , ...</td>\n",
       "      <td>[you, sir, are, my, hero, any, chance, you, re...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \\\n",
       "0             0        0       0       0              0   \n",
       "1             0        0       0       0              0   \n",
       "2             0        0       0       0              0   \n",
       "3             0        0       0       0              0   \n",
       "4             0        0       0       0              0   \n",
       "\n",
       "                                          text_clean  \\\n",
       "0  explanation\\nwhy the edits made under my usern...   \n",
       "1  daww he matches this background colour i am se...   \n",
       "2  hey man i am really not trying to edit war it ...   \n",
       "3  \\nmore\\ni cannot make any real suggestions on ...   \n",
       "4  you sir are my hero any chance you remember wh...   \n",
       "\n",
       "                                    snowball_stemmer  \\\n",
       "0  [e, x, p, l, a, n, a, t, i, o, n, \\n, w, h, y,...   \n",
       "1  [d, a, w, w,  , h, e,  , m, a, t, c, h, e, s, ...   \n",
       "2  [h, e, y,  , m, a, n,  , i,  , a, m,  , r, e, ...   \n",
       "3  [\\n, m, o, r, e, \\n, i,  , c, a, n, n, o, t,  ...   \n",
       "4  [y, o, u,  , s, i, r,  , a, r, e,  , m, y,  , ...   \n",
       "\n",
       "                                           tokenized  \n",
       "0  [explanation, why, the, edits, made, under, my...  \n",
       "1  [daww, he, matches, this, background, colour, ...  \n",
       "2  [hey, man, i, am, really, not, trying, to, edi...  \n",
       "3  [more, i, can, not, make, any, real, suggestio...  \n",
       "4  [you, sir, are, my, hero, any, chance, you, re...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenizing the tweet base texts.\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "train_df['tokenized'] = train_df['text_clean'].apply(word_tokenize)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Remove Stop Words (or/and Frequent words/ Rare words):\n",
    "Stop words are common words in any language that occur with a high frequency but do not deliver meaningful information for the whole sentence. For example, {“a”, “about”, “above”, “across”, “after”, “afterward”, “again”, ...} can be considered as stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T00:12:48.389545Z",
     "iopub.status.busy": "2023-03-23T00:12:48.388994Z",
     "iopub.status.idle": "2023-03-23T00:12:51.079800Z",
     "shell.execute_reply": "2023-03-23T00:12:51.078467Z",
     "shell.execute_reply.started": "2023-03-23T00:12:48.389499Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/linhtrinh/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>snowball_stemmer</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>stopwords_removed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>explanation\\nwhy the edits made under my usern...</td>\n",
       "      <td>[e, x, p, l, a, n, a, t, i, o, n, \\n, w, h, y,...</td>\n",
       "      <td>[explanation, why, the, edits, made, under, my...</td>\n",
       "      <td>[explanation, edits, made, username, hardcore,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>daww he matches this background colour i am se...</td>\n",
       "      <td>[d, a, w, w,  , h, e,  , m, a, t, c, h, e, s, ...</td>\n",
       "      <td>[daww, he, matches, this, background, colour, ...</td>\n",
       "      <td>[daww, matches, background, colour, seemingly,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>hey man i am really not trying to edit war it ...</td>\n",
       "      <td>[h, e, y,  , m, a, n,  , i,  , a, m,  , r, e, ...</td>\n",
       "      <td>[hey, man, i, am, really, not, trying, to, edi...</td>\n",
       "      <td>[hey, man, really, trying, edit, war, guy, con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>\\nmore\\ni cannot make any real suggestions on ...</td>\n",
       "      <td>[\\n, m, o, r, e, \\n, i,  , c, a, n, n, o, t,  ...</td>\n",
       "      <td>[more, i, can, not, make, any, real, suggestio...</td>\n",
       "      <td>[make, real, suggestions, improvement, wondere...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>you sir are my hero any chance you remember wh...</td>\n",
       "      <td>[y, o, u,  , s, i, r,  , a, r, e,  , m, y,  , ...</td>\n",
       "      <td>[you, sir, are, my, hero, any, chance, you, re...</td>\n",
       "      <td>[sir, hero, chance, remember, page]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \\\n",
       "0             0        0       0       0              0   \n",
       "1             0        0       0       0              0   \n",
       "2             0        0       0       0              0   \n",
       "3             0        0       0       0              0   \n",
       "4             0        0       0       0              0   \n",
       "\n",
       "                                          text_clean  \\\n",
       "0  explanation\\nwhy the edits made under my usern...   \n",
       "1  daww he matches this background colour i am se...   \n",
       "2  hey man i am really not trying to edit war it ...   \n",
       "3  \\nmore\\ni cannot make any real suggestions on ...   \n",
       "4  you sir are my hero any chance you remember wh...   \n",
       "\n",
       "                                    snowball_stemmer  \\\n",
       "0  [e, x, p, l, a, n, a, t, i, o, n, \\n, w, h, y,...   \n",
       "1  [d, a, w, w,  , h, e,  , m, a, t, c, h, e, s, ...   \n",
       "2  [h, e, y,  , m, a, n,  , i,  , a, m,  , r, e, ...   \n",
       "3  [\\n, m, o, r, e, \\n, i,  , c, a, n, n, o, t,  ...   \n",
       "4  [y, o, u,  , s, i, r,  , a, r, e,  , m, y,  , ...   \n",
       "\n",
       "                                           tokenized  \\\n",
       "0  [explanation, why, the, edits, made, under, my...   \n",
       "1  [daww, he, matches, this, background, colour, ...   \n",
       "2  [hey, man, i, am, really, not, trying, to, edi...   \n",
       "3  [more, i, can, not, make, any, real, suggestio...   \n",
       "4  [you, sir, are, my, hero, any, chance, you, re...   \n",
       "\n",
       "                                   stopwords_removed  \n",
       "0  [explanation, edits, made, username, hardcore,...  \n",
       "1  [daww, matches, background, colour, seemingly,...  \n",
       "2  [hey, man, really, trying, edit, war, guy, con...  \n",
       "3  [make, real, suggestions, improvement, wondere...  \n",
       "4                [sir, hero, chance, remember, page]  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing stopwords.\n",
    "nltk.download(\"stopwords\")\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop = set(stopwords.words('english'))\n",
    "train_df['stopwords_removed'] = train_df['tokenized'].apply(lambda x: [word for word in x if word not in stop])\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Stemming\n",
    "Stemming is a process of extracting a root word - identifying a common stem among various forms (e.g., singular and plural noun form) of a word, for example, the words \"gardening\", \"gardener\" or \"gardens\" share the same stem, garden. Stemming uproots suffixes from words to merge words with similar meanings under their standard stem.\n",
    "\n",
    "There are three major stemming algorithms in use nowadays:\n",
    "\n",
    "- Porter - PorterStemmer()): This stemming algorithm is an older one. It’s from the 1980s and its main concern is removing the common endings to words so that they can be resolved to a common form. It’s not too complex and development on it is frozen. Typically, it’s a nice starting basic stemmer, but it’s not really advised to use it for any production/complex application. Instead, it has its place in research as a nice, basic stemming algorithm that can guarantee reproducibility. It also is a very gentle stemming algorithm when compared to others.\n",
    "\n",
    "- Snowball - LancasterStemmer(): This algorithm is also known as the Porter2 stemming algorithm. It is almost universally accepted as better than the Porter stemmer, even being acknowledged as such by the individual who created the Porter stemmer. That being said, it is also more aggressive than the Porter stemmer. A lot of the things added to the Snowball stemmer were because of issues noticed with the Porter stemmer. There is about a 5% difference in the way that Snowball stems versus Porter.\n",
    "\n",
    "- Lancaster - SnowballStemmer(): Just for fun, the Lancaster stemming algorithm is another algorithm that you can use. This one is the most aggressive stemming algorithm of the bunch. However, if you use the stemmer in NLTK, you can add your own custom rules to this algorithm very easily. It’s a good choice for that. One complaint around this stemming algorithm though is that it sometimes is overly aggressive and can really transform words into strange stems. Just make sure it does what you want it to before you go with this option!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Snowball"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T00:17:51.198949Z",
     "iopub.status.busy": "2023-03-23T00:17:51.197605Z",
     "iopub.status.idle": "2023-03-23T00:17:51.206217Z",
     "shell.execute_reply": "2023-03-23T00:17:51.204510Z",
     "shell.execute_reply.started": "2023-03-23T00:17:51.198896Z"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "def snowball_stemmer(text):\n",
    "    \"\"\"\n",
    "        Stem words in list of tokenized words with SnowballStemmer\n",
    "    \"\"\"\n",
    "    stemmer = nltk.SnowballStemmer(\"english\")\n",
    "    stems = [stemmer.stem(i) for i in text]\n",
    "    return stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T00:18:02.213634Z",
     "iopub.status.busy": "2023-03-23T00:18:02.212747Z",
     "iopub.status.idle": "2023-03-23T00:19:30.633190Z",
     "shell.execute_reply": "2023-03-23T00:19:30.632013Z",
     "shell.execute_reply.started": "2023-03-23T00:18:02.213584Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>snowball_stemmer</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>stopwords_removed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>explanation\\nwhy the edits made under my usern...</td>\n",
       "      <td>[explan, edit, made, usernam, hardcor, metalli...</td>\n",
       "      <td>[explanation, why, the, edits, made, under, my...</td>\n",
       "      <td>[explanation, edits, made, username, hardcore,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>daww he matches this background colour i am se...</td>\n",
       "      <td>[daww, match, background, colour, seem, stuck,...</td>\n",
       "      <td>[daww, he, matches, this, background, colour, ...</td>\n",
       "      <td>[daww, matches, background, colour, seemingly,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>hey man i am really not trying to edit war it ...</td>\n",
       "      <td>[hey, man, realli, tri, edit, war, guy, consta...</td>\n",
       "      <td>[hey, man, i, am, really, not, trying, to, edi...</td>\n",
       "      <td>[hey, man, really, trying, edit, war, guy, con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>\\nmore\\ni cannot make any real suggestions on ...</td>\n",
       "      <td>[make, real, suggest, improv, wonder, section,...</td>\n",
       "      <td>[more, i, can, not, make, any, real, suggestio...</td>\n",
       "      <td>[make, real, suggestions, improvement, wondere...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>you sir are my hero any chance you remember wh...</td>\n",
       "      <td>[sir, hero, chanc, rememb, page]</td>\n",
       "      <td>[you, sir, are, my, hero, any, chance, you, re...</td>\n",
       "      <td>[sir, hero, chance, remember, page]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \\\n",
       "0             0        0       0       0              0   \n",
       "1             0        0       0       0              0   \n",
       "2             0        0       0       0              0   \n",
       "3             0        0       0       0              0   \n",
       "4             0        0       0       0              0   \n",
       "\n",
       "                                          text_clean  \\\n",
       "0  explanation\\nwhy the edits made under my usern...   \n",
       "1  daww he matches this background colour i am se...   \n",
       "2  hey man i am really not trying to edit war it ...   \n",
       "3  \\nmore\\ni cannot make any real suggestions on ...   \n",
       "4  you sir are my hero any chance you remember wh...   \n",
       "\n",
       "                                    snowball_stemmer  \\\n",
       "0  [explan, edit, made, usernam, hardcor, metalli...   \n",
       "1  [daww, match, background, colour, seem, stuck,...   \n",
       "2  [hey, man, realli, tri, edit, war, guy, consta...   \n",
       "3  [make, real, suggest, improv, wonder, section,...   \n",
       "4                   [sir, hero, chanc, rememb, page]   \n",
       "\n",
       "                                           tokenized  \\\n",
       "0  [explanation, why, the, edits, made, under, my...   \n",
       "1  [daww, he, matches, this, background, colour, ...   \n",
       "2  [hey, man, i, am, really, not, trying, to, edi...   \n",
       "3  [more, i, can, not, make, any, real, suggestio...   \n",
       "4  [you, sir, are, my, hero, any, chance, you, re...   \n",
       "\n",
       "                                   stopwords_removed  \n",
       "0  [explanation, edits, made, username, hardcore,...  \n",
       "1  [daww, matches, background, colour, seemingly,...  \n",
       "2  [hey, man, really, trying, edit, war, guy, con...  \n",
       "3  [make, real, suggestions, improvement, wondere...  \n",
       "4                [sir, hero, chance, remember, page]  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['snowball_stemmer'] = train_df['stopwords_removed'].apply(lambda x: snowball_stemmer(x))\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lancaster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T00:19:42.823944Z",
     "iopub.status.busy": "2023-03-23T00:19:42.823463Z",
     "iopub.status.idle": "2023-03-23T00:19:42.831744Z",
     "shell.execute_reply": "2023-03-23T00:19:42.830046Z",
     "shell.execute_reply.started": "2023-03-23T00:19:42.823905Z"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.stem import LancasterStemmer\n",
    "\n",
    "def lancaster_stemmer(text):\n",
    "    \"\"\"\n",
    "        Stem words in list of tokenized words with LancasterStemmer\n",
    "    \"\"\"\n",
    "    stemmer = nltk.LancasterStemmer()\n",
    "    stems = [stemmer.stem(i) for i in text]\n",
    "    return stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T01:32:43.341970Z",
     "iopub.status.busy": "2023-03-23T01:32:43.341173Z",
     "iopub.status.idle": "2023-03-23T01:34:41.486280Z",
     "shell.execute_reply": "2023-03-23T01:34:41.484684Z",
     "shell.execute_reply.started": "2023-03-23T01:32:43.341892Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>stopwords_removed</th>\n",
       "      <th>snowball_stemmer</th>\n",
       "      <th>lancaster_stemmer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>explanation\\nwhy the edits made under my usern...</td>\n",
       "      <td>[explanation, why, the, edits, made, under, my...</td>\n",
       "      <td>[explanation, edits, made, username, hardcore,...</td>\n",
       "      <td>[explan, edit, made, usernam, hardcor, metalli...</td>\n",
       "      <td>[expl, edit, mad, usernam, hardc, metallic, fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>daww he matches this background colour i am se...</td>\n",
       "      <td>[daww, he, matches, this, background, colour, ...</td>\n",
       "      <td>[daww, matches, background, colour, seemingly,...</td>\n",
       "      <td>[daww, match, background, colour, seem, stuck,...</td>\n",
       "      <td>[daww, match, background, colo, seem, stuck, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>hey man i am really not trying to edit war it ...</td>\n",
       "      <td>[hey, man, i, am, really, not, trying, to, edi...</td>\n",
       "      <td>[hey, man, really, trying, edit, war, guy, con...</td>\n",
       "      <td>[hey, man, realli, tri, edit, war, guy, consta...</td>\n",
       "      <td>[hey, man, real, try, edit, war, guy, const, r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>\\nmore\\ni cannot make any real suggestions on ...</td>\n",
       "      <td>[more, i, can, not, make, any, real, suggestio...</td>\n",
       "      <td>[make, real, suggestions, improvement, wondere...</td>\n",
       "      <td>[make, real, suggest, improv, wonder, section,...</td>\n",
       "      <td>[mak, real, suggest, improv, wond, sect, stat,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>you sir are my hero any chance you remember wh...</td>\n",
       "      <td>[you, sir, are, my, hero, any, chance, you, re...</td>\n",
       "      <td>[sir, hero, chance, remember, page]</td>\n",
       "      <td>[sir, hero, chanc, rememb, page]</td>\n",
       "      <td>[sir, hero, chant, rememb, pag]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>00025465d4725e87</td>\n",
       "      <td>\"\\n\\nCongratulations from me as well, use the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>\\n\\ncongratulations from me as well use the to...</td>\n",
       "      <td>[congratulations, from, me, as, well, use, the...</td>\n",
       "      <td>[congratulations, well, use, tools, well, talk]</td>\n",
       "      <td>[congratul, well, use, tool, well, talk]</td>\n",
       "      <td>[congrat, wel, us, tool, wel, talk]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0002bcb3da6cb337</td>\n",
       "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>cocksucker before you piss around on my work</td>\n",
       "      <td>[cocksucker, before, you, piss, around, on, my...</td>\n",
       "      <td>[cocksucker, piss, around, work]</td>\n",
       "      <td>[cocksuck, piss, around, work]</td>\n",
       "      <td>[cocksuck, piss, around, work]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>00031b1e95af7921</td>\n",
       "      <td>Your vandalism to the Matt Shirvington article...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>your vandalism to the matt shirvington article...</td>\n",
       "      <td>[your, vandalism, to, the, matt, shirvington, ...</td>\n",
       "      <td>[vandalism, matt, shirvington, article, revert...</td>\n",
       "      <td>[vandal, matt, shirvington, articl, revert, pl...</td>\n",
       "      <td>[vand, mat, shirvington, artic, revert, pleas,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>00037261f536c51d</td>\n",
       "      <td>Sorry if the word 'nonsense' was offensive to ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>sorry if the word nonsense was offensive to yo...</td>\n",
       "      <td>[sorry, if, the, word, nonsense, was, offensiv...</td>\n",
       "      <td>[sorry, word, nonsense, offensive, anyway, int...</td>\n",
       "      <td>[sorri, word, nonsens, offens, anyway, intend,...</td>\n",
       "      <td>[sorry, word, nonsens, offend, anyway, intend,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>00040093b2687caa</td>\n",
       "      <td>alignment on this subject and which are contra...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>alignment on this subject and which are contra...</td>\n",
       "      <td>[alignment, on, this, subject, and, which, are...</td>\n",
       "      <td>[alignment, subject, contrary, dulithgow]</td>\n",
       "      <td>[align, subject, contrari, dulithgow]</td>\n",
       "      <td>[align, subject, cont, dulithgow]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0005300084f90edc</td>\n",
       "      <td>\"\\nFair use rationale for Image:Wonju.jpg\\n\\nT...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>\\nfair use rationale for imagewonjujpg\\n\\nthan...</td>\n",
       "      <td>[fair, use, rationale, for, imagewonjujpg, tha...</td>\n",
       "      <td>[fair, use, rationale, imagewonjujpg, thanks, ...</td>\n",
       "      <td>[fair, use, rational, imagewonjujpg, thank, up...</td>\n",
       "      <td>[fair, us, rat, imagewonjujpg, thank, upload, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>00054a5e18b50dd4</td>\n",
       "      <td>bbq \\n\\nbe a man and lets discuss it-maybe ove...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>bbq \\n\\nbe a man and let us discuss itmaybe ov...</td>\n",
       "      <td>[bbq, be, a, man, and, let, us, discuss, itmay...</td>\n",
       "      <td>[bbq, man, let, us, discuss, itmaybe, phone]</td>\n",
       "      <td>[bbq, man, let, us, discuss, itmayb, phone]</td>\n",
       "      <td>[bbq, man, let, us, discuss, itmayb, phon]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0005c987bdfc9d4b</td>\n",
       "      <td>Hey... what is it..\\n@ | talk .\\nWhat is it......</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>hey what is it\\n  talk \\nwhat is it an exclusi...</td>\n",
       "      <td>[hey, what, is, it, talk, what, is, it, an, ex...</td>\n",
       "      <td>[hey, talk, exclusive, group, wp, talibanswho,...</td>\n",
       "      <td>[hey, talk, exclus, group, wp, talibanswho, go...</td>\n",
       "      <td>[hey, talk, exclud, group, wp, talibanswho, go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0006f16e4e9f292e</td>\n",
       "      <td>Before you start throwing accusations and warn...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>before you start throwing accusations and warn...</td>\n",
       "      <td>[before, you, start, throwing, accusations, an...</td>\n",
       "      <td>[start, throwing, accusations, warnings, let, ...</td>\n",
       "      <td>[start, throw, accus, warn, let, us, review, e...</td>\n",
       "      <td>[start, throwing, accus, warn, let, us, review...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>00070ef96486d6f9</td>\n",
       "      <td>Oh, and the girl above started her arguments w...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>oh and the girl above started her arguments wi...</td>\n",
       "      <td>[oh, and, the, girl, above, started, her, argu...</td>\n",
       "      <td>[oh, girl, started, arguments, stuck, nose, be...</td>\n",
       "      <td>[oh, girl, start, argument, stuck, nose, belon...</td>\n",
       "      <td>[oh, girl, start, argu, stuck, nos, belong, be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>00078f8ce7eb276d</td>\n",
       "      <td>\"\\n\\nJuelz Santanas Age\\n\\nIn 2002, Juelz Sant...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>\\n\\njuelz santanas age\\n\\nin 2002 juelz santan...</td>\n",
       "      <td>[juelz, santanas, age, in, 2002, juelz, santan...</td>\n",
       "      <td>[juelz, santanas, age, 2002, juelz, santana, 1...</td>\n",
       "      <td>[juelz, santana, age, 2002, juelz, santana, 18...</td>\n",
       "      <td>[juelz, santana, ag, 2002, juelz, santan, 18, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0007e25b2121310b</td>\n",
       "      <td>Bye! \\n\\nDon't look, come or think of comming ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>bye \\n\\ndo not look come or think of comming b...</td>\n",
       "      <td>[bye, do, not, look, come, or, think, of, comm...</td>\n",
       "      <td>[bye, look, come, think, comming, back, tosser]</td>\n",
       "      <td>[bye, look, come, think, com, back, tosser]</td>\n",
       "      <td>[bye, look, com, think, com, back, toss]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>000897889268bc93</td>\n",
       "      <td>REDIRECT Talk:Voydan Pop Georgiev- Chernodrinski</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>redirect talkvoydan pop georgiev chernodrinski</td>\n",
       "      <td>[redirect, talkvoydan, pop, georgiev, chernodr...</td>\n",
       "      <td>[redirect, talkvoydan, pop, georgiev, chernodr...</td>\n",
       "      <td>[redirect, talkvoydan, pop, georgiev, chernodr...</td>\n",
       "      <td>[redirect, talkvoyd, pop, georgiev, chernodrinsk]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0009801bd85e5806</td>\n",
       "      <td>The Mitsurugi point made no sense - why not ar...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>the mitsurugi point made no sense  why not arg...</td>\n",
       "      <td>[the, mitsurugi, point, made, no, sense, why, ...</td>\n",
       "      <td>[mitsurugi, point, made, sense, argue, include...</td>\n",
       "      <td>[mitsurugi, point, made, sens, argu, includ, h...</td>\n",
       "      <td>[mitsurug, point, mad, sens, argu, includ, hin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0009eaea3325de8c</td>\n",
       "      <td>Don't mean to bother you \\n\\nI see that you're...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>do not mean to bother you \\n\\ni see that you a...</td>\n",
       "      <td>[do, not, mean, to, bother, you, i, see, that,...</td>\n",
       "      <td>[mean, bother, see, writing, something, regard...</td>\n",
       "      <td>[mean, bother, see, write, someth, regard, rem...</td>\n",
       "      <td>[mean, both, see, writ, someth, regard, remov,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id                                       comment_text  \\\n",
       "0   0000997932d777bf  Explanation\\nWhy the edits made under my usern...   \n",
       "1   000103f0d9cfb60f  D'aww! He matches this background colour I'm s...   \n",
       "2   000113f07ec002fd  Hey man, I'm really not trying to edit war. It...   \n",
       "3   0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...   \n",
       "4   0001d958c54c6e35  You, sir, are my hero. Any chance you remember...   \n",
       "5   00025465d4725e87  \"\\n\\nCongratulations from me as well, use the ...   \n",
       "6   0002bcb3da6cb337       COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK   \n",
       "7   00031b1e95af7921  Your vandalism to the Matt Shirvington article...   \n",
       "8   00037261f536c51d  Sorry if the word 'nonsense' was offensive to ...   \n",
       "9   00040093b2687caa  alignment on this subject and which are contra...   \n",
       "10  0005300084f90edc  \"\\nFair use rationale for Image:Wonju.jpg\\n\\nT...   \n",
       "11  00054a5e18b50dd4  bbq \\n\\nbe a man and lets discuss it-maybe ove...   \n",
       "12  0005c987bdfc9d4b  Hey... what is it..\\n@ | talk .\\nWhat is it......   \n",
       "13  0006f16e4e9f292e  Before you start throwing accusations and warn...   \n",
       "14  00070ef96486d6f9  Oh, and the girl above started her arguments w...   \n",
       "15  00078f8ce7eb276d  \"\\n\\nJuelz Santanas Age\\n\\nIn 2002, Juelz Sant...   \n",
       "16  0007e25b2121310b  Bye! \\n\\nDon't look, come or think of comming ...   \n",
       "17  000897889268bc93   REDIRECT Talk:Voydan Pop Georgiev- Chernodrinski   \n",
       "18  0009801bd85e5806  The Mitsurugi point made no sense - why not ar...   \n",
       "19  0009eaea3325de8c  Don't mean to bother you \\n\\nI see that you're...   \n",
       "\n",
       "    toxic  severe_toxic  obscene  threat  insult  identity_hate  \\\n",
       "0       0             0        0       0       0              0   \n",
       "1       0             0        0       0       0              0   \n",
       "2       0             0        0       0       0              0   \n",
       "3       0             0        0       0       0              0   \n",
       "4       0             0        0       0       0              0   \n",
       "5       0             0        0       0       0              0   \n",
       "6       1             1        1       0       1              0   \n",
       "7       0             0        0       0       0              0   \n",
       "8       0             0        0       0       0              0   \n",
       "9       0             0        0       0       0              0   \n",
       "10      0             0        0       0       0              0   \n",
       "11      0             0        0       0       0              0   \n",
       "12      1             0        0       0       0              0   \n",
       "13      0             0        0       0       0              0   \n",
       "14      0             0        0       0       0              0   \n",
       "15      0             0        0       0       0              0   \n",
       "16      1             0        0       0       0              0   \n",
       "17      0             0        0       0       0              0   \n",
       "18      0             0        0       0       0              0   \n",
       "19      0             0        0       0       0              0   \n",
       "\n",
       "                                           text_clean  \\\n",
       "0   explanation\\nwhy the edits made under my usern...   \n",
       "1   daww he matches this background colour i am se...   \n",
       "2   hey man i am really not trying to edit war it ...   \n",
       "3   \\nmore\\ni cannot make any real suggestions on ...   \n",
       "4   you sir are my hero any chance you remember wh...   \n",
       "5   \\n\\ncongratulations from me as well use the to...   \n",
       "6        cocksucker before you piss around on my work   \n",
       "7   your vandalism to the matt shirvington article...   \n",
       "8   sorry if the word nonsense was offensive to yo...   \n",
       "9   alignment on this subject and which are contra...   \n",
       "10  \\nfair use rationale for imagewonjujpg\\n\\nthan...   \n",
       "11  bbq \\n\\nbe a man and let us discuss itmaybe ov...   \n",
       "12  hey what is it\\n  talk \\nwhat is it an exclusi...   \n",
       "13  before you start throwing accusations and warn...   \n",
       "14  oh and the girl above started her arguments wi...   \n",
       "15  \\n\\njuelz santanas age\\n\\nin 2002 juelz santan...   \n",
       "16  bye \\n\\ndo not look come or think of comming b...   \n",
       "17     redirect talkvoydan pop georgiev chernodrinski   \n",
       "18  the mitsurugi point made no sense  why not arg...   \n",
       "19  do not mean to bother you \\n\\ni see that you a...   \n",
       "\n",
       "                                            tokenized  \\\n",
       "0   [explanation, why, the, edits, made, under, my...   \n",
       "1   [daww, he, matches, this, background, colour, ...   \n",
       "2   [hey, man, i, am, really, not, trying, to, edi...   \n",
       "3   [more, i, can, not, make, any, real, suggestio...   \n",
       "4   [you, sir, are, my, hero, any, chance, you, re...   \n",
       "5   [congratulations, from, me, as, well, use, the...   \n",
       "6   [cocksucker, before, you, piss, around, on, my...   \n",
       "7   [your, vandalism, to, the, matt, shirvington, ...   \n",
       "8   [sorry, if, the, word, nonsense, was, offensiv...   \n",
       "9   [alignment, on, this, subject, and, which, are...   \n",
       "10  [fair, use, rationale, for, imagewonjujpg, tha...   \n",
       "11  [bbq, be, a, man, and, let, us, discuss, itmay...   \n",
       "12  [hey, what, is, it, talk, what, is, it, an, ex...   \n",
       "13  [before, you, start, throwing, accusations, an...   \n",
       "14  [oh, and, the, girl, above, started, her, argu...   \n",
       "15  [juelz, santanas, age, in, 2002, juelz, santan...   \n",
       "16  [bye, do, not, look, come, or, think, of, comm...   \n",
       "17  [redirect, talkvoydan, pop, georgiev, chernodr...   \n",
       "18  [the, mitsurugi, point, made, no, sense, why, ...   \n",
       "19  [do, not, mean, to, bother, you, i, see, that,...   \n",
       "\n",
       "                                    stopwords_removed  \\\n",
       "0   [explanation, edits, made, username, hardcore,...   \n",
       "1   [daww, matches, background, colour, seemingly,...   \n",
       "2   [hey, man, really, trying, edit, war, guy, con...   \n",
       "3   [make, real, suggestions, improvement, wondere...   \n",
       "4                 [sir, hero, chance, remember, page]   \n",
       "5     [congratulations, well, use, tools, well, talk]   \n",
       "6                    [cocksucker, piss, around, work]   \n",
       "7   [vandalism, matt, shirvington, article, revert...   \n",
       "8   [sorry, word, nonsense, offensive, anyway, int...   \n",
       "9           [alignment, subject, contrary, dulithgow]   \n",
       "10  [fair, use, rationale, imagewonjujpg, thanks, ...   \n",
       "11       [bbq, man, let, us, discuss, itmaybe, phone]   \n",
       "12  [hey, talk, exclusive, group, wp, talibanswho,...   \n",
       "13  [start, throwing, accusations, warnings, let, ...   \n",
       "14  [oh, girl, started, arguments, stuck, nose, be...   \n",
       "15  [juelz, santanas, age, 2002, juelz, santana, 1...   \n",
       "16    [bye, look, come, think, comming, back, tosser]   \n",
       "17  [redirect, talkvoydan, pop, georgiev, chernodr...   \n",
       "18  [mitsurugi, point, made, sense, argue, include...   \n",
       "19  [mean, bother, see, writing, something, regard...   \n",
       "\n",
       "                                     snowball_stemmer  \\\n",
       "0   [explan, edit, made, usernam, hardcor, metalli...   \n",
       "1   [daww, match, background, colour, seem, stuck,...   \n",
       "2   [hey, man, realli, tri, edit, war, guy, consta...   \n",
       "3   [make, real, suggest, improv, wonder, section,...   \n",
       "4                    [sir, hero, chanc, rememb, page]   \n",
       "5            [congratul, well, use, tool, well, talk]   \n",
       "6                      [cocksuck, piss, around, work]   \n",
       "7   [vandal, matt, shirvington, articl, revert, pl...   \n",
       "8   [sorri, word, nonsens, offens, anyway, intend,...   \n",
       "9               [align, subject, contrari, dulithgow]   \n",
       "10  [fair, use, rational, imagewonjujpg, thank, up...   \n",
       "11        [bbq, man, let, us, discuss, itmayb, phone]   \n",
       "12  [hey, talk, exclus, group, wp, talibanswho, go...   \n",
       "13  [start, throw, accus, warn, let, us, review, e...   \n",
       "14  [oh, girl, start, argument, stuck, nose, belon...   \n",
       "15  [juelz, santana, age, 2002, juelz, santana, 18...   \n",
       "16        [bye, look, come, think, com, back, tosser]   \n",
       "17  [redirect, talkvoydan, pop, georgiev, chernodr...   \n",
       "18  [mitsurugi, point, made, sens, argu, includ, h...   \n",
       "19  [mean, bother, see, write, someth, regard, rem...   \n",
       "\n",
       "                                    lancaster_stemmer  \n",
       "0   [expl, edit, mad, usernam, hardc, metallic, fa...  \n",
       "1   [daww, match, background, colo, seem, stuck, t...  \n",
       "2   [hey, man, real, try, edit, war, guy, const, r...  \n",
       "3   [mak, real, suggest, improv, wond, sect, stat,...  \n",
       "4                     [sir, hero, chant, rememb, pag]  \n",
       "5                 [congrat, wel, us, tool, wel, talk]  \n",
       "6                      [cocksuck, piss, around, work]  \n",
       "7   [vand, mat, shirvington, artic, revert, pleas,...  \n",
       "8   [sorry, word, nonsens, offend, anyway, intend,...  \n",
       "9                   [align, subject, cont, dulithgow]  \n",
       "10  [fair, us, rat, imagewonjujpg, thank, upload, ...  \n",
       "11         [bbq, man, let, us, discuss, itmayb, phon]  \n",
       "12  [hey, talk, exclud, group, wp, talibanswho, go...  \n",
       "13  [start, throwing, accus, warn, let, us, review...  \n",
       "14  [oh, girl, start, argu, stuck, nos, belong, be...  \n",
       "15  [juelz, santana, ag, 2002, juelz, santan, 18, ...  \n",
       "16           [bye, look, com, think, com, back, toss]  \n",
       "17  [redirect, talkvoyd, pop, georgiev, chernodrinsk]  \n",
       "18  [mitsurug, point, mad, sens, argu, includ, hin...  \n",
       "19  [mean, both, see, writ, someth, regard, remov,...  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['lancaster_stemmer'] = train_df['stopwords_removed'].apply(lambda x: lancaster_stemmer(x))\n",
    "train_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(153164, 2)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>Yo bitch Ja Rule is more succesful then you'll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>== From RfC == \\n\\n The title is fine as it is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>\" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>:If you have a look back at the source, the in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>I don't anonymously edit articles at all.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text\n",
       "0  00001cee341fdb12  Yo bitch Ja Rule is more succesful then you'll...\n",
       "1  0000247867823ef7  == From RfC == \\n\\n The title is fine as it is...\n",
       "2  00013b17ad220c46  \" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...\n",
       "3  00017563c3f7919a  :If you have a look back at the source, the in...\n",
       "4  00017695ad8997eb          I don't anonymously edit articles at all."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_df = pd.read_csv(\"/Users/linhtrinh/Downloads/test.csv\")\n",
    "display(test_df.shape, test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[\"text_clean\"] = test_df[\"comment_text\"].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['text_clean'] = test_df['text_clean'].apply(lambda x: contractions.fix(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[\"text_clean\"] = test_df[\"text_clean\"].apply(lambda x: remove_URL(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[\"text_clean\"] = test_df[\"text_clean\"].apply(lambda x: remove_html(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[\"text_clean\"] = test_df[\"text_clean\"].apply(lambda x: remove_non_ascii(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[\"text_clean\"] = test_df[\"text_clean\"].apply(lambda x: remove_special_characters(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[\"text_clean\"] = test_df[\"text_clean\"].apply(lambda x: remove_punct(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>Yo bitch Ja Rule is more succesful then you'll...</td>\n",
       "      <td>yo bitch ja rule is more succesful then you wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>== From RfC == \\n\\n The title is fine as it is...</td>\n",
       "      <td>from rfc  \\n\\n the title is fine as it is i a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>\" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...</td>\n",
       "      <td>\\n\\n  sources  \\n\\n  zawe ashton on lapland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>:If you have a look back at the source, the in...</td>\n",
       "      <td>if you have a look back at the source the info...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>I don't anonymously edit articles at all.</td>\n",
       "      <td>i do not anonymously edit articles at all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153159</th>\n",
       "      <td>fffcd0960ee309b5</td>\n",
       "      <td>. \\n i totally agree, this stuff is nothing bu...</td>\n",
       "      <td>\\n i totally agree this stuff is nothing but ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153160</th>\n",
       "      <td>fffd7a9a6eb32c16</td>\n",
       "      <td>== Throw from out field to home plate. == \\n\\n...</td>\n",
       "      <td>throw from out field to home plate  \\n\\n does...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153161</th>\n",
       "      <td>fffda9e8d6fafa9e</td>\n",
       "      <td>\" \\n\\n == Okinotorishima categories == \\n\\n I ...</td>\n",
       "      <td>\\n\\n  okinotorishima categories  \\n\\n i see y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153162</th>\n",
       "      <td>fffe8f1340a79fc2</td>\n",
       "      <td>\" \\n\\n == \"\"One of the founding nations of the...</td>\n",
       "      <td>\\n\\n  one of the founding nations of the eu  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153163</th>\n",
       "      <td>ffffce3fb183ee80</td>\n",
       "      <td>\" \\n :::Stop already. Your bullshit is not wel...</td>\n",
       "      <td>\\n stop already your bullshit is not welcome ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>153164 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                                       comment_text  \\\n",
       "0       00001cee341fdb12  Yo bitch Ja Rule is more succesful then you'll...   \n",
       "1       0000247867823ef7  == From RfC == \\n\\n The title is fine as it is...   \n",
       "2       00013b17ad220c46  \" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...   \n",
       "3       00017563c3f7919a  :If you have a look back at the source, the in...   \n",
       "4       00017695ad8997eb          I don't anonymously edit articles at all.   \n",
       "...                  ...                                                ...   \n",
       "153159  fffcd0960ee309b5  . \\n i totally agree, this stuff is nothing bu...   \n",
       "153160  fffd7a9a6eb32c16  == Throw from out field to home plate. == \\n\\n...   \n",
       "153161  fffda9e8d6fafa9e  \" \\n\\n == Okinotorishima categories == \\n\\n I ...   \n",
       "153162  fffe8f1340a79fc2  \" \\n\\n == \"\"One of the founding nations of the...   \n",
       "153163  ffffce3fb183ee80  \" \\n :::Stop already. Your bullshit is not wel...   \n",
       "\n",
       "                                               text_clean  \n",
       "0       yo bitch ja rule is more succesful then you wi...  \n",
       "1        from rfc  \\n\\n the title is fine as it is i a...  \n",
       "2        \\n\\n  sources  \\n\\n  zawe ashton on lapland       \n",
       "3       if you have a look back at the source the info...  \n",
       "4               i do not anonymously edit articles at all  \n",
       "...                                                   ...  \n",
       "153159   \\n i totally agree this stuff is nothing but ...  \n",
       "153160   throw from out field to home plate  \\n\\n does...  \n",
       "153161   \\n\\n  okinotorishima categories  \\n\\n i see y...  \n",
       "153162   \\n\\n  one of the founding nations of the eu  ...  \n",
       "153163   \\n stop already your bullshit is not welcome ...  \n",
       "\n",
       "[153164 rows x 3 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[\"text_clean\"] = test_df[\"text_clean\"].apply(lambda x: other_clean(x))\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/linhtrinh/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>Yo bitch Ja Rule is more succesful then you'll...</td>\n",
       "      <td>yo bitch ja rule is more succesful then you wi...</td>\n",
       "      <td>[yo, bitch, ja, rule, is, more, succesful, the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>== From RfC == \\n\\n The title is fine as it is...</td>\n",
       "      <td>from rfc  \\n\\n the title is fine as it is i a...</td>\n",
       "      <td>[from, rfc, the, title, is, fine, as, it, is, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>\" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...</td>\n",
       "      <td>\\n\\n  sources  \\n\\n  zawe ashton on lapland</td>\n",
       "      <td>[sources, zawe, ashton, on, lapland]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>:If you have a look back at the source, the in...</td>\n",
       "      <td>if you have a look back at the source the info...</td>\n",
       "      <td>[if, you, have, a, look, back, at, the, source...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>I don't anonymously edit articles at all.</td>\n",
       "      <td>i do not anonymously edit articles at all</td>\n",
       "      <td>[i, do, not, anonymously, edit, articles, at, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  \\\n",
       "0  00001cee341fdb12  Yo bitch Ja Rule is more succesful then you'll...   \n",
       "1  0000247867823ef7  == From RfC == \\n\\n The title is fine as it is...   \n",
       "2  00013b17ad220c46  \" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...   \n",
       "3  00017563c3f7919a  :If you have a look back at the source, the in...   \n",
       "4  00017695ad8997eb          I don't anonymously edit articles at all.   \n",
       "\n",
       "                                          text_clean  \\\n",
       "0  yo bitch ja rule is more succesful then you wi...   \n",
       "1   from rfc  \\n\\n the title is fine as it is i a...   \n",
       "2   \\n\\n  sources  \\n\\n  zawe ashton on lapland        \n",
       "3  if you have a look back at the source the info...   \n",
       "4          i do not anonymously edit articles at all   \n",
       "\n",
       "                                           tokenized  \n",
       "0  [yo, bitch, ja, rule, is, more, succesful, the...  \n",
       "1  [from, rfc, the, title, is, fine, as, it, is, ...  \n",
       "2               [sources, zawe, ashton, on, lapland]  \n",
       "3  [if, you, have, a, look, back, at, the, source...  \n",
       "4  [i, do, not, anonymously, edit, articles, at, ...  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenizing the tweet base texts.\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "test_df['tokenized'] = test_df['text_clean'].apply(word_tokenize)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/linhtrinh/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>stopwords_removed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>Yo bitch Ja Rule is more succesful then you'll...</td>\n",
       "      <td>yo bitch ja rule is more succesful then you wi...</td>\n",
       "      <td>[yo, bitch, ja, rule, is, more, succesful, the...</td>\n",
       "      <td>[yo, bitch, ja, rule, succesful, ever, hating,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>== From RfC == \\n\\n The title is fine as it is...</td>\n",
       "      <td>from rfc  \\n\\n the title is fine as it is i a...</td>\n",
       "      <td>[from, rfc, the, title, is, fine, as, it, is, ...</td>\n",
       "      <td>[rfc, title, fine, going]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>\" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...</td>\n",
       "      <td>\\n\\n  sources  \\n\\n  zawe ashton on lapland</td>\n",
       "      <td>[sources, zawe, ashton, on, lapland]</td>\n",
       "      <td>[sources, zawe, ashton, lapland]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>:If you have a look back at the source, the in...</td>\n",
       "      <td>if you have a look back at the source the info...</td>\n",
       "      <td>[if, you, have, a, look, back, at, the, source...</td>\n",
       "      <td>[look, back, source, information, updated, cor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>I don't anonymously edit articles at all.</td>\n",
       "      <td>i do not anonymously edit articles at all</td>\n",
       "      <td>[i, do, not, anonymously, edit, articles, at, ...</td>\n",
       "      <td>[anonymously, edit, articles]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  \\\n",
       "0  00001cee341fdb12  Yo bitch Ja Rule is more succesful then you'll...   \n",
       "1  0000247867823ef7  == From RfC == \\n\\n The title is fine as it is...   \n",
       "2  00013b17ad220c46  \" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...   \n",
       "3  00017563c3f7919a  :If you have a look back at the source, the in...   \n",
       "4  00017695ad8997eb          I don't anonymously edit articles at all.   \n",
       "\n",
       "                                          text_clean  \\\n",
       "0  yo bitch ja rule is more succesful then you wi...   \n",
       "1   from rfc  \\n\\n the title is fine as it is i a...   \n",
       "2   \\n\\n  sources  \\n\\n  zawe ashton on lapland        \n",
       "3  if you have a look back at the source the info...   \n",
       "4          i do not anonymously edit articles at all   \n",
       "\n",
       "                                           tokenized  \\\n",
       "0  [yo, bitch, ja, rule, is, more, succesful, the...   \n",
       "1  [from, rfc, the, title, is, fine, as, it, is, ...   \n",
       "2               [sources, zawe, ashton, on, lapland]   \n",
       "3  [if, you, have, a, look, back, at, the, source...   \n",
       "4  [i, do, not, anonymously, edit, articles, at, ...   \n",
       "\n",
       "                                   stopwords_removed  \n",
       "0  [yo, bitch, ja, rule, succesful, ever, hating,...  \n",
       "1                          [rfc, title, fine, going]  \n",
       "2                   [sources, zawe, ashton, lapland]  \n",
       "3  [look, back, source, information, updated, cor...  \n",
       "4                      [anonymously, edit, articles]  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing stopwords.\n",
    "nltk.download(\"stopwords\")\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop = set(stopwords.words('english'))\n",
    "test_df['stopwords_removed'] = test_df['tokenized'].apply(lambda x: [word for word in x if word not in stop])\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>stopwords_removed</th>\n",
       "      <th>snowball_stemmer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>Yo bitch Ja Rule is more succesful then you'll...</td>\n",
       "      <td>yo bitch ja rule is more succesful then you wi...</td>\n",
       "      <td>[yo, bitch, ja, rule, is, more, succesful, the...</td>\n",
       "      <td>[yo, bitch, ja, rule, succesful, ever, hating,...</td>\n",
       "      <td>[yo, bitch, ja, rule, succes, ever, hate, sad,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>== From RfC == \\n\\n The title is fine as it is...</td>\n",
       "      <td>from rfc  \\n\\n the title is fine as it is i a...</td>\n",
       "      <td>[from, rfc, the, title, is, fine, as, it, is, ...</td>\n",
       "      <td>[rfc, title, fine, going]</td>\n",
       "      <td>[rfc, titl, fine, go]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>\" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...</td>\n",
       "      <td>\\n\\n  sources  \\n\\n  zawe ashton on lapland</td>\n",
       "      <td>[sources, zawe, ashton, on, lapland]</td>\n",
       "      <td>[sources, zawe, ashton, lapland]</td>\n",
       "      <td>[sourc, zaw, ashton, lapland]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>:If you have a look back at the source, the in...</td>\n",
       "      <td>if you have a look back at the source the info...</td>\n",
       "      <td>[if, you, have, a, look, back, at, the, source...</td>\n",
       "      <td>[look, back, source, information, updated, cor...</td>\n",
       "      <td>[look, back, sourc, inform, updat, correct, fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>I don't anonymously edit articles at all.</td>\n",
       "      <td>i do not anonymously edit articles at all</td>\n",
       "      <td>[i, do, not, anonymously, edit, articles, at, ...</td>\n",
       "      <td>[anonymously, edit, articles]</td>\n",
       "      <td>[anonym, edit, articl]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  \\\n",
       "0  00001cee341fdb12  Yo bitch Ja Rule is more succesful then you'll...   \n",
       "1  0000247867823ef7  == From RfC == \\n\\n The title is fine as it is...   \n",
       "2  00013b17ad220c46  \" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...   \n",
       "3  00017563c3f7919a  :If you have a look back at the source, the in...   \n",
       "4  00017695ad8997eb          I don't anonymously edit articles at all.   \n",
       "\n",
       "                                          text_clean  \\\n",
       "0  yo bitch ja rule is more succesful then you wi...   \n",
       "1   from rfc  \\n\\n the title is fine as it is i a...   \n",
       "2   \\n\\n  sources  \\n\\n  zawe ashton on lapland        \n",
       "3  if you have a look back at the source the info...   \n",
       "4          i do not anonymously edit articles at all   \n",
       "\n",
       "                                           tokenized  \\\n",
       "0  [yo, bitch, ja, rule, is, more, succesful, the...   \n",
       "1  [from, rfc, the, title, is, fine, as, it, is, ...   \n",
       "2               [sources, zawe, ashton, on, lapland]   \n",
       "3  [if, you, have, a, look, back, at, the, source...   \n",
       "4  [i, do, not, anonymously, edit, articles, at, ...   \n",
       "\n",
       "                                   stopwords_removed  \\\n",
       "0  [yo, bitch, ja, rule, succesful, ever, hating,...   \n",
       "1                          [rfc, title, fine, going]   \n",
       "2                   [sources, zawe, ashton, lapland]   \n",
       "3  [look, back, source, information, updated, cor...   \n",
       "4                      [anonymously, edit, articles]   \n",
       "\n",
       "                                    snowball_stemmer  \n",
       "0  [yo, bitch, ja, rule, succes, ever, hate, sad,...  \n",
       "1                              [rfc, titl, fine, go]  \n",
       "2                      [sourc, zaw, ashton, lapland]  \n",
       "3  [look, back, sourc, inform, updat, correct, fo...  \n",
       "4                             [anonym, edit, articl]  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['snowball_stemmer'] = test_df['stopwords_removed'].apply(lambda x: snowball_stemmer(x))\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>stopwords_removed</th>\n",
       "      <th>snowball_stemmer</th>\n",
       "      <th>lancaster_stemmer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>Yo bitch Ja Rule is more succesful then you'll...</td>\n",
       "      <td>yo bitch ja rule is more succesful then you wi...</td>\n",
       "      <td>[yo, bitch, ja, rule, is, more, succesful, the...</td>\n",
       "      <td>[yo, bitch, ja, rule, succesful, ever, hating,...</td>\n",
       "      <td>[yo, bitch, ja, rule, succes, ever, hate, sad,...</td>\n",
       "      <td>[yo, bitch, ja, rul, succes, ev, hat, sad, mof...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>== From RfC == \\n\\n The title is fine as it is...</td>\n",
       "      <td>from rfc  \\n\\n the title is fine as it is i a...</td>\n",
       "      <td>[from, rfc, the, title, is, fine, as, it, is, ...</td>\n",
       "      <td>[rfc, title, fine, going]</td>\n",
       "      <td>[rfc, titl, fine, go]</td>\n",
       "      <td>[rfc, titl, fin, going]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>\" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...</td>\n",
       "      <td>\\n\\n  sources  \\n\\n  zawe ashton on lapland</td>\n",
       "      <td>[sources, zawe, ashton, on, lapland]</td>\n",
       "      <td>[sources, zawe, ashton, lapland]</td>\n",
       "      <td>[sourc, zaw, ashton, lapland]</td>\n",
       "      <td>[sourc, zaw, ashton, lapland]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>:If you have a look back at the source, the in...</td>\n",
       "      <td>if you have a look back at the source the info...</td>\n",
       "      <td>[if, you, have, a, look, back, at, the, source...</td>\n",
       "      <td>[look, back, source, information, updated, cor...</td>\n",
       "      <td>[look, back, sourc, inform, updat, correct, fo...</td>\n",
       "      <td>[look, back, sourc, inform, upd, correct, form...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>I don't anonymously edit articles at all.</td>\n",
       "      <td>i do not anonymously edit articles at all</td>\n",
       "      <td>[i, do, not, anonymously, edit, articles, at, ...</td>\n",
       "      <td>[anonymously, edit, articles]</td>\n",
       "      <td>[anonym, edit, articl]</td>\n",
       "      <td>[anonym, edit, artic]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  \\\n",
       "0  00001cee341fdb12  Yo bitch Ja Rule is more succesful then you'll...   \n",
       "1  0000247867823ef7  == From RfC == \\n\\n The title is fine as it is...   \n",
       "2  00013b17ad220c46  \" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...   \n",
       "3  00017563c3f7919a  :If you have a look back at the source, the in...   \n",
       "4  00017695ad8997eb          I don't anonymously edit articles at all.   \n",
       "\n",
       "                                          text_clean  \\\n",
       "0  yo bitch ja rule is more succesful then you wi...   \n",
       "1   from rfc  \\n\\n the title is fine as it is i a...   \n",
       "2   \\n\\n  sources  \\n\\n  zawe ashton on lapland        \n",
       "3  if you have a look back at the source the info...   \n",
       "4          i do not anonymously edit articles at all   \n",
       "\n",
       "                                           tokenized  \\\n",
       "0  [yo, bitch, ja, rule, is, more, succesful, the...   \n",
       "1  [from, rfc, the, title, is, fine, as, it, is, ...   \n",
       "2               [sources, zawe, ashton, on, lapland]   \n",
       "3  [if, you, have, a, look, back, at, the, source...   \n",
       "4  [i, do, not, anonymously, edit, articles, at, ...   \n",
       "\n",
       "                                   stopwords_removed  \\\n",
       "0  [yo, bitch, ja, rule, succesful, ever, hating,...   \n",
       "1                          [rfc, title, fine, going]   \n",
       "2                   [sources, zawe, ashton, lapland]   \n",
       "3  [look, back, source, information, updated, cor...   \n",
       "4                      [anonymously, edit, articles]   \n",
       "\n",
       "                                    snowball_stemmer  \\\n",
       "0  [yo, bitch, ja, rule, succes, ever, hate, sad,...   \n",
       "1                              [rfc, titl, fine, go]   \n",
       "2                      [sourc, zaw, ashton, lapland]   \n",
       "3  [look, back, sourc, inform, updat, correct, fo...   \n",
       "4                             [anonym, edit, articl]   \n",
       "\n",
       "                                   lancaster_stemmer  \n",
       "0  [yo, bitch, ja, rul, succes, ev, hat, sad, mof...  \n",
       "1                            [rfc, titl, fin, going]  \n",
       "2                      [sourc, zaw, ashton, lapland]  \n",
       "3  [look, back, sourc, inform, upd, correct, form...  \n",
       "4                              [anonym, edit, artic]  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['lancaster_stemmer'] = test_df['stopwords_removed'].apply(lambda x: lancaster_stemmer(x))\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv('cleanedtest.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_cols = ['toxic', 'severe_toxic', 'obscene', 'threat','insult', 'identity_hate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of train : 159571\n",
      "size of test : 153164\n",
      "--------------------\n",
      "toxic            15294\n",
      "obscene           8449\n",
      "insult            7877\n",
      "severe_toxic      1595\n",
      "identity_hate     1405\n",
      "threat             478\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# data size\n",
    "print('size of train : {}'.format(len(train_df)))\n",
    "print('size of test : {}'.format(len(test_df)))\n",
    "print('-'*20)\n",
    "print(train_df[target_cols].sum().sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "y = train_df[target_cols]\n",
    "column_dict = {}\n",
    "for i in list(y.columns):\n",
    "    column_dict[i]=y[i].sum()\n",
    "\n",
    "column_list = sorted(column_dict,key=column_dict.get,reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "sns.barplot(column_list,y.sum().sort_values(ascending=False))\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare model to fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning data again\n",
    "\n",
    "Note: My tokenized data can't be passed into vectorization method, I decided to clean and stem again (still use snowball stemmer), text will be tokenized and vectorized later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer(language='english')\n",
    "stopwords_ = stopwords.words('english')\n",
    "def simple_clear(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(\"[^a-zA-Z]\", ' ', text)\n",
    "    text = re.sub('<.*?>','',text)\n",
    "    text = re.sub(r\"https?:\\/\\/t.co\\/[A-Za-z0-9]+\", \"\", text)\n",
    "    text = re.sub('\\[|\\(.*\\]|\\)','', text) \n",
    "    text = re.sub(\"(\\\\W)\",\" \",text) \n",
    "    text = re.sub('\\S*\\d\\S*\\s*','', text)  \n",
    "    text = text.split()\n",
    "    text = [stemmer.stem(word) for word in text if not word in set(stopwords_)]\n",
    "    text = ' '.join(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    explan edit made usernam hardcor metallica fan...\n",
       "1    daww match background colour seem stuck thank ...\n",
       "2    hey man realli tri edit war guy constant remov...\n",
       "3    cannot make real suggest improv wonder section...\n",
       "4                           sir hero chanc rememb page\n",
       "Name: clean, dtype: object"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['clean'] = train_df['text_clean'].apply(simple_clear)\n",
    "train_df['clean'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_raw = train_df['clean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_raw , y, test_size=0.2, random_state=42,shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "look_train = {}\n",
    "for i in list(y_train.columns):\n",
    "    look_train[i]=y_train[i].sum()\n",
    "\n",
    "column_list_train = sorted(look_train,key=look_train.get,reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "sns.barplot(column_list_train,y_train.sum().sort_values(ascending=False))\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transforming cleaned text after tokenizations and stemming in TF IDF to a matrix of numerical vectors, where each row represents a document and each column represents a word\n",
    "- TF-IDF stands for Term Frequency-Inverse Document Frequency, which is a common technique used in natural language processing for text feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectorizer = TfidfVectorizer(\n",
    "    strip_accents='unicode',                 \n",
    "    token_pattern=r'\\w{1,}',    \n",
    "    ngram_range=(1, 3),         \n",
    "    stop_words = stopwords_,\n",
    "    sublinear_tf=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(ngram_range=(1, 3),\n",
       "                stop_words=['i', 'me', 'my', 'myself', 'we', 'our', 'ours',\n",
       "                            'ourselves', 'you', \"you're\", \"you've\", \"you'll\",\n",
       "                            \"you'd\", 'your', 'yours', 'yourself', 'yourselves',\n",
       "                            'he', 'him', 'his', 'himself', 'she', \"she's\",\n",
       "                            'her', 'hers', 'herself', 'it', \"it's\", 'its',\n",
       "                            'itself', ...],\n",
       "                strip_accents='unicode', sublinear_tf=True,\n",
       "                token_pattern='\\\\w{1,}')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectorizer.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_transformed = word_vectorizer.transform(X_train)\n",
    "X_test_transformed = word_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the shape of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_transformed (127656, 5308709)\n",
      "y_train (127656, 6)\n",
      "X_test_transformed (31915, 5308709)\n",
      "y_test (31915, 6)\n"
     ]
    }
   ],
   "source": [
    "print('X_train_transformed', X_train_transformed.shape)\n",
    "print('y_train', y_train.shape)\n",
    "print('X_test_transformed', X_test_transformed.shape)\n",
    "print('y_test', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>140030</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159124</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60006</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65432</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154979</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119879</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103694</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131932</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146867</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121958</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>127656 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        toxic  severe_toxic  obscene  threat  insult  identity_hate\n",
       "140030      1             0        0       0       0              0\n",
       "159124      0             0        0       0       0              0\n",
       "60006       0             0        0       0       0              0\n",
       "65432       0             0        0       0       0              0\n",
       "154979      0             0        0       0       0              0\n",
       "...       ...           ...      ...     ...     ...            ...\n",
       "119879      0             0        0       0       0              0\n",
       "103694      0             0        0       0       0              0\n",
       "131932      1             0        0       0       0              0\n",
       "146867      0             0        0       0       0              0\n",
       "121958      0             0        0       0       0              0\n",
       "\n",
       "[127656 rows x 6 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression with ROC_AUC score for Train Data\n",
    "\n",
    "- ROC-AUC is a metric used to evaluate the performance of binary classification models. ROC stands for Receiver Operating Characteristic, and AUC stands for Area Under the ROC Curve.\n",
    "\n",
    "- In practice, the ROC-AUC is often used to compare the performance of different binary classification models or to tune the hyperparameters of a model. A higher ROC-AUC score generally indicates a better-performing model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best_score = 0.9665445916615891\n",
      "Best_params = {'Log_reg__C': 1, 'Log_reg__class_weight': 'balanced', 'Log_reg__penalty': 'l2', 'Log_reg__solver': 'liblinear'}\n",
      "Roc_auc at test:  = 0.8947000153209258\n",
      "CPU times: user 25 s, sys: 9.65 s, total: 34.6 s\n",
      "Wall time: 1min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pipe_Log_reg =  Pipeline([(\"Log_reg\", LogisticRegression(random_state = 42,max_iter = 10000))])\n",
    "params = {'Log_reg__penalty': ['l2'],\n",
    "          'Log_reg__C': [0.5,0.75,1],\n",
    "          'Log_reg__class_weight': ['balanced',None],\n",
    "          'Log_reg__solver': ['liblinear']}\n",
    "Log_reg = GridSearchCV(pipe_Log_reg,params,scoring='roc_auc',return_train_score=True,n_jobs=-1)\n",
    "Log_reg.fit(X_train_transformed,y_train.toxic)\n",
    "print(f'Best_score = {Log_reg.best_score_}')\n",
    "print(f'Best_params = {Log_reg.best_params_}')\n",
    "print(f'Roc_auc at test:  = {roc_auc_score(y_test.toxic,Log_reg.predict(X_test_transformed))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: I did logistic regression with comment_text column instead of text_clean column, score is approximately 90%, much lower than cleaned text (~ 97%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=LogisticRegression(C=1, class_weight='balanced',\n",
       "                                                 random_state=42,\n",
       "                                                 solver='liblinear'))"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg = LogisticRegression(C = 1, penalty='l2', solver = 'liblinear',class_weight = 'balanced', random_state=42)\n",
    "\n",
    "classifier_ovr_log = OneVsRestClassifier(log_reg)\n",
    "classifier_ovr_log.fit(X_train_transformed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score Test: 0.89864564472017\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.84      0.73      3056\n",
      "           1       0.27      0.86      0.41       321\n",
      "           2       0.67      0.88      0.76      1715\n",
      "           3       0.17      0.77      0.28        74\n",
      "           4       0.56      0.85      0.67      1614\n",
      "           5       0.24      0.74      0.36       294\n",
      "\n",
      "   micro avg       0.54      0.85      0.66      7074\n",
      "   macro avg       0.42      0.82      0.53      7074\n",
      "weighted avg       0.59      0.85      0.69      7074\n",
      " samples avg       0.06      0.08      0.07      7074\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"ROC AUC Score Test:\", roc_auc_score(y_test, classifier_ovr_log.predict(X_test_transformed)))\n",
    "print(classification_report(y_test, classifier_ovr_log.predict(X_test_transformed)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.9395\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Fit the model and make predictions\n",
    "Log_reg.fit(X_train_transformed, y_train.toxic)\n",
    "y_pred = Log_reg.predict(X_test_transformed)\n",
    "\n",
    "# Print the accuracy score\n",
    "accuracy = accuracy_score(y_test.toxic, y_pred)\n",
    "print(f'Accuracy score: {accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params: {'Log_reg__C': 0.5, 'Log_reg__class_weight': 'balanced', 'Log_reg__penalty': 'l2', 'Log_reg__solver': 'liblinear'}\n",
      "Train score: 0.9960\n",
      "Validation score: 0.9637\n",
      "\n",
      "Params: {'Log_reg__C': 0.5, 'Log_reg__class_weight': None, 'Log_reg__penalty': 'l2', 'Log_reg__solver': 'liblinear'}\n",
      "Train score: 0.9870\n",
      "Validation score: 0.9601\n",
      "\n",
      "Params: {'Log_reg__C': 0.75, 'Log_reg__class_weight': 'balanced', 'Log_reg__penalty': 'l2', 'Log_reg__solver': 'liblinear'}\n",
      "Train score: 0.9975\n",
      "Validation score: 0.9655\n",
      "\n",
      "Params: {'Log_reg__C': 0.75, 'Log_reg__class_weight': None, 'Log_reg__penalty': 'l2', 'Log_reg__solver': 'liblinear'}\n",
      "Train score: 0.9913\n",
      "Validation score: 0.9626\n",
      "\n",
      "Params: {'Log_reg__C': 1, 'Log_reg__class_weight': 'balanced', 'Log_reg__penalty': 'l2', 'Log_reg__solver': 'liblinear'}\n",
      "Train score: 0.9982\n",
      "Validation score: 0.9665\n",
      "\n",
      "Params: {'Log_reg__C': 1, 'Log_reg__class_weight': None, 'Log_reg__penalty': 'l2', 'Log_reg__solver': 'liblinear'}\n",
      "Train score: 0.9939\n",
      "Validation score: 0.9641\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "Log_reg.fit(X_train_transformed, y_train.toxic)\n",
    "\n",
    "# Print the train score and validation score for each parameter combination\n",
    "results = Log_reg.cv_results_\n",
    "for i in range(len(results['params'])):\n",
    "    print(f\"Params: {results['params'][i]}\")\n",
    "    print(f\"Train score: {results['mean_train_score'][i]:.4f}\")\n",
    "    print(f\"Validation score: {results['mean_test_score'][i]:.4f}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression with Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    yo bitch ja rule succes ever hate sad mofuckas...\n",
       "1                                     rfc titl fine go\n",
       "2                             sourc zaw ashton lapland\n",
       "3    look back sourc inform updat correct form gues...\n",
       "4                                   anonym edit articl\n",
       "Name: clean, dtype: object"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['clean'] = test_df['text_clean'].apply(simple_clear)\n",
    "test_df['clean'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_sub = word_vectorizer.transform(test_df['clean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=LogisticRegression(C=1, class_weight='balanced',\n",
       "                                                 random_state=42,\n",
       "                                                 solver='liblinear'))"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg = LogisticRegression(C = 1, penalty='l2', solver = 'liblinear',class_weight = 'balanced', random_state=42)\n",
    "\n",
    "classifier_ovr_log = OneVsRestClassifier(log_reg)\n",
    "classifier_ovr_log.fit(X_train_transformed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier_ovr_log.predict(X_test_sub)\n",
    "y_pred_df = pd.DataFrame(y_pred,columns=y.columns)\n",
    "submission_df = pd.concat([test_df.id, y_pred_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   toxic  severe_toxic  obscene  threat  insult  identity_hate\n",
       "0      1             1        1       1       1              1\n",
       "1      0             0        0       0       0              0\n",
       "2      0             0        0       0       0              0\n",
       "3      0             0        0       0       0              0\n",
       "4      0             0        0       0       0              0"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
